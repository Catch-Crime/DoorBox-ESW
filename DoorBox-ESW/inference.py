import cv2
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.models import efficientnet_b0, mobilenet_v3_small
import timm  # GhostNetì„ ìœ„í•´ í•„ìš”
import serial
import threading
import time
import json
import os
import boto3
from datetime import datetime, timezone
import pytz  # ì‹œê°„ëŒ€ ì„¤ì •ìš©
from collections import deque
import logging
from botocore.exceptions import ClientError
import warnings

# Warning ë©”ì‹œì§€ ì™„ì „íˆ ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore")
import torchvision  

# ì„¤ì • íŒŒì¼ import
import config

# ================= PIR, OLED, RGB LED ê´€ë ¨ ì¶”ê°€ =================
# GPIO library detection
try:
    from gpiozero import LED, MotionSensor
    GPIO_METHOD = "gpiozero"
    print("âœ… Using gpiozero library")
except ImportError:
    GPIO_METHOD = "direct"
    print("âœ… Using direct GPIO control")

# I2C OLED library
try:
    import smbus2 as smbus
    I2C_AVAILABLE = True
    print("âœ… Using smbus2 for OLED")
except ImportError:
    try:
        import smbus
        I2C_AVAILABLE = True
        print("âœ… Using smbus for OLED")
    except ImportError:
        I2C_AVAILABLE = False
        print("âŒ I2C library not available")

from PIL import Image, ImageDraw, ImageFont

class RGBController:
    """RGB LED Controller (Common Cathode)"""
    
    def __init__(self):
        self.pins = {'RED': 18, 'GREEN': 23, 'BLUE': 24}  # GPIO numbers
        
        if GPIO_METHOD == "gpiozero":
            self._init_gpiozero()
        else:
            self._init_direct()
        
        # Turn off all LEDs initially
        self.set_rgb(0, 0, 0)
        print("âœ… RGB LED initialized (Common Cathode)")
    
    def _init_gpiozero(self):
        """Initialize using gpiozero"""
        self.red_led = LED(18)    # Pin 12
        self.green_led = LED(23)  # Pin 16  
        self.blue_led = LED(24)   # Pin 18
    
    def _init_direct(self):
        """Initialize using direct GPIO control"""
        # Cleanup existing GPIO
        for pin in self.pins.values():
            try:
                with open('/sys/class/gpio/unexport', 'w') as f:
                    f.write(str(pin))
            except:
                pass
        
        # Export and setup
        for pin in self.pins.values():
            with open('/sys/class/gpio/export', 'w') as f:
                f.write(str(pin))
            time.sleep(0.1)
            with open(f'/sys/class/gpio/gpio{pin}/direction', 'w') as f:
                f.write('out')
    
    def _set_pin_value(self, pin, value):
        """Set GPIO pin value (direct method)"""
        try:
            with open(f'/sys/class/gpio/gpio{pin}/value', 'w') as f:
                f.write(str(value))
        except Exception as e:
            print(f"GPIO {pin} error: {e}")
    
    def set_rgb(self, r, g, b):
        """Set RGB color (0-255 each)"""
        # Convert 0-255 to 0/1 (threshold at 128)
        red_val = 1 if r > 128 else 0
        green_val = 1 if g > 128 else 0
        blue_val = 1 if b > 128 else 0
        
        if GPIO_METHOD == "gpiozero":
            # gpiozero: on()=HIGH, off()=LOW
            if red_val:
                self.red_led.on()
            else:
                self.red_led.off()
                
            if green_val:
                self.green_led.on()
            else:
                self.green_led.off()
                
            if blue_val:
                self.blue_led.on()
            else:
                self.blue_led.off()
        else:
            # Direct GPIO control
            self._set_pin_value(self.pins['RED'], red_val)
            self._set_pin_value(self.pins['GREEN'], green_val)
            self._set_pin_value(self.pins['BLUE'], blue_val)
    
    def set_color_by_name(self, color_name):
        """Set color by predefined names"""
        colors = {
            "red": (255, 0, 0),
            "green": (0, 255, 0),
            "blue": (0, 0, 255),
            "yellow": (255, 255, 0),
            "white": (255, 255, 255),
            "purple": (255, 0, 255),
            "off": (0, 0, 0)
        }
        if color_name in colors:
            self.set_rgb(*colors[color_name])
    
    def blink_purple(self, times=3, interval=0.3):
        """ë³´ë¼ìƒ‰ LEDë¥¼ ì§€ì •ëœ íšŸìˆ˜ë§Œí¼ ê¹œë¹¡ì„"""
        for i in range(times):
            self.set_rgb(255, 0, 255)  # ë³´ë¼ìƒ‰ ì¼œê¸°
            time.sleep(interval)
            self.set_rgb(0, 0, 0)      # LED ë„ê¸°
            time.sleep(interval)
    
    def cleanup(self):
        """Cleanup GPIO resources"""
        try:
            self.set_rgb(0, 0, 0)
        except:
            pass  # ì´ë¯¸ ì¢…ë£Œëœ ê²½ìš° ë¬´ì‹œ
        
        if GPIO_METHOD == "gpiozero":
            try:
                if hasattr(self, 'red_led') and self.red_led:
                    self.red_led.close()
                if hasattr(self, 'green_led') and self.green_led:
                    self.green_led.close()
                if hasattr(self, 'blue_led') and self.blue_led:
                    self.blue_led.close()
            except:
                pass
        else:
            for pin in self.pins.values():
                try:
                    with open('/sys/class/gpio/unexport', 'w') as f:
                        f.write(str(pin))
                except:
                    pass

class OLEDDisplay:
    """Simple OLED Display Controller"""
    
    def __init__(self):
        if not I2C_AVAILABLE:
            raise Exception("I2C library not available")
        
        self.bus = smbus.SMBus(1)
        self.addr = 0x3C
        self.width = 128
        self.height = 64
        
        # Initialize OLED
        init_sequence = [
            0xAE, 0xD5, 0x80, 0xA8, 0x3F, 0xD3, 0x00, 0x40,
            0x8D, 0x14, 0x20, 0x00, 0xA1, 0xC8, 0xDA, 0x12,
            0x81, 0x7F, 0xD9, 0x22, 0xDB, 0x20, 0xA4, 0xA6, 0xAF
        ]
        
        for cmd in init_sequence:
            self.bus.write_byte_data(self.addr, 0x00, cmd)
        
        # Load font
        try:
            self.font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 10)
            self.font_small = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 8)
        except:
            self.font = ImageFont.load_default()
            self.font_small = ImageFont.load_default()
        
        self.clear()
        print("âœ… OLED display initialized")
    
    def clear(self):
        """Clear the display"""
        for page in range(8):
            self.bus.write_byte_data(self.addr, 0x00, 0xB0 + page)
            self.bus.write_byte_data(self.addr, 0x00, 0x00)
            self.bus.write_byte_data(self.addr, 0x00, 0x10)
            
            for col in range(128):
                self.bus.write_byte_data(self.addr, 0x40, 0x00)
    
    def display_text(self, lines):
        """Display text lines with improved error handling"""
        if not hasattr(self, 'display_lock'):
            self.display_lock = threading.Lock()
        
        with self.display_lock:
            try:
                image = Image.new("1", (self.width, self.height))
                draw = ImageDraw.Draw(image)
                
                y = 0
                for i, line in enumerate(lines[:6]):
                    font = self.font if i == 0 else self.font_small
                    # ë¬¸ìì—´ ê¸¸ì´ ì œí•œìœ¼ë¡œ ê¹¨ì§ ë°©ì§€
                    line_str = str(line)[:20] if len(str(line)) > 20 else str(line)
                    draw.text((0, y), line_str, font=font, fill=1)
                    y += 11 if i == 0 else 10
                
                pixels = list(image.getdata())
                
                # OLED ì—…ë°ì´íŠ¸ë¥¼ ë” ì•ˆì •ì ìœ¼ë¡œ
                for page in range(8):
                    try:
                        self.bus.write_byte_data(self.addr, 0x00, 0xB0 + page)
                        self.bus.write_byte_data(self.addr, 0x00, 0x00)
                        self.bus.write_byte_data(self.addr, 0x00, 0x10)
                        
                        for col in range(128):
                            byte_val = 0
                            for bit in range(8):
                                pixel_y = page * 8 + bit
                                if pixel_y < 64:
                                    pixel_idx = pixel_y * 128 + col
                                    if pixel_idx < len(pixels) and pixels[pixel_idx]:
                                        byte_val |= (1 << bit)
                            
                            self.bus.write_byte_data(self.addr, 0x40, byte_val)
                    except Exception as e:
                        # í˜ì´ì§€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ì‹œ ê³„ì† ì§„í–‰
                        continue
                        
            except Exception as e:
                # ì „ì²´ ë””ìŠ¤í”Œë ˆì´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ì‹œ ì¡°ìš©íˆ ë¬´ì‹œ
                pass

class PIRSensor:
    """PIR Motion Sensor Controller"""
    
    def __init__(self):
        self.pir_pin = 14  # GPIO14 (Pin 8)
        self.last_detection = None
        self.detection_count = 0
        self.motion_callback = None
        
        if GPIO_METHOD == "gpiozero":
            self._init_gpiozero()
        else:
            self._init_direct()
        
        print("âœ… PIR sensor initialized (GPIO14)")
    
    def _init_gpiozero(self):
        """Initialize PIR using gpiozero"""
        self.pir_sensor = MotionSensor(self.pir_pin)
        self.pir_sensor.when_motion = self._motion_detected
    
    def _init_direct(self):
        """Initialize PIR using direct GPIO"""
        try:
            with open('/sys/class/gpio/unexport', 'w') as f:
                f.write(str(self.pir_pin))
        except:
            pass
        
        with open('/sys/class/gpio/export', 'w') as f:
            f.write(str(self.pir_pin))
        time.sleep(0.1)
        
        with open(f'/sys/class/gpio/gpio{self.pir_pin}/direction', 'w') as f:
            f.write('in')
        
        self.last_state = 0
    
    def set_callback(self, callback):
        """Set motion detection callback"""
        self.motion_callback = callback
    
    def _motion_detected(self):
        """Motion detection callback"""
        self.detection_count += 1
        self.last_detection = datetime.now()
        
        print(f"ğŸš¶ PIR Motion detected! Count: {self.detection_count}")
        print(f"   Time: {self.last_detection.strftime('%H:%M:%S')}")
        
        if self.motion_callback:
            self.motion_callback()
    
    def check_motion_direct(self):
        """Check motion for direct GPIO method"""
        if GPIO_METHOD != "direct":
            return False
            
        try:
            with open(f'/sys/class/gpio/gpio{self.pir_pin}/value', 'r') as f:
                current_state = int(f.read().strip())
            
            if current_state == 1 and self.last_state == 0:
                self.last_state = current_state
                self._motion_detected()
                return True
            
            self.last_state = current_state
            return False
            
        except Exception as e:
            print(f"PIR read error: {e}")
            return False
    
    def get_status(self):
        """Get current PIR status"""
        if GPIO_METHOD == "gpiozero":
            try:
                current_value = self.pir_sensor.motion_detected
            except:
                current_value = False
        else:
            try:
                with open(f'/sys/class/gpio/gpio{self.pir_pin}/value', 'r') as f:
                    current_value = int(f.read().strip())
            except:
                current_value = 0
        
        return {
            'active': bool(current_value),
            'count': self.detection_count,
            'last_detection': self.last_detection
        }
    
    def cleanup(self):
        """Cleanup PIR resources"""
        if GPIO_METHOD == "gpiozero":
            self.pir_sensor.close()
        else:
            try:
                with open('/sys/class/gpio/unexport', 'w') as f:
                    f.write(str(self.pir_pin))
            except:
                pass

# ================= ê¸°ì¡´ DoorBox í´ë˜ìŠ¤ í™•ì¥ =================

class DoorBoxInferenceSystem:
    def __init__(self):
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        config.create_directories()
        
        # AWS S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        self._setup_aws_client()
        
        # ê¸°ë³¸ ì„¤ì •
        self.rtsp_url = config.RTSP_URL
        self.serial_port = config.SERIAL_PORT
        self.serial_baudrate = config.SERIAL_BAUDRATE
        self.device_id = config.DEVICE_ID
        
        # êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
        self.cap = None
        self.ser = None
        self.running = False
        
        # â˜… PIR, OLED, RGB LED ì´ˆê¸°í™”
        self._init_hardware_components()
        
        # ëª¨ë¸ë“¤ ë¡œë“œ
        self._load_models()
        
        # ë¹„ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”
        self._init_video_recorder()
        
        # S3 ì—…ë¡œë” ì´ˆê¸°í™”
        self._init_s3_uploader()
        
        # ìŠ¤ë ˆë“œ ê´€ë¦¬
        self.rtsp_thread = None
        self.serial_thread = None
        self.pir_monitor_thread = None
        
        # í”„ë ˆì„ ë²„í¼
        self.latest_frame = None
        self.frame_lock = threading.Lock()
        
        # ì—…ë¡œë“œ ìƒíƒœ ì´ˆê¸°í™” (OLED ì˜¤ë¥˜ í•´ê²°)
        self.upload_status = {"active": False, "queue_size": 0}
        
        # PIR ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬
        self.system_state = "STANDBY"  # STANDBY, PIR_DETECTED, INFERENCE_ACTIVE
        self.pir_detection_time = None
        self.inference_timeout = 15.0  # 15ì´ˆ
        # ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ê°ì§€ ë° ìº¡ì²˜ ê´€ë¦¬
        self.green_box_detected = False
        self.first_green_box_time = None
        self.last_capture_time = 0
        self.capture_delay = 2.0  # ì²« ê°ì§€ í›„ 2ì´ˆ ì§€ì—°
        self.capture_interval = 5.0  # 5ì´ˆ ê°„ê²©ìœ¼ë¡œ ìº¡ì²˜
        
        # OLED ë¶„ë¥˜ ê²°ê³¼ í‘œì‹œ ê´€ë¦¬
        self.face_detection_results = None
        self.classification_display_start = None
        self.classification_display_duration = 3.0  # 3ì´ˆ ë™ì•ˆ í‘œì‹œ
        
        # ê¸°ì¡´ ìº¡ì²˜ ìƒíƒœ ê´€ë¦¬
        self.capture_in_progress = False
        self.capture_lock = threading.Lock()
        self.last_successful_capture_time = 0
        self.capture_timer = None
        self.pending_captures = 0
        
        # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ì¹´ìš´í„°
        self.filename_counter = {}
        self.filename_lock = threading.Lock()
        
        self.logger.info("DoorBox ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (PIR í†µí•©)")
    
    def _init_hardware_components(self):
        """PIR, OLED, RGB LED ì´ˆê¸°í™”"""
        # RGB LED ì´ˆê¸°í™”
        try:
            self.rgb = RGBController()
            self.rgb_available = True
            self.rgb.set_color_by_name("red")  # ì´ˆê¸° ëŒ€ê¸° ìƒíƒœëŠ” ë¹¨ê°„ìƒ‰
            self.logger.info("âœ… RGB LED ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"RGB LED ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.rgb_available = False
        
        # OLED ë””ìŠ¤í”Œë ˆì´ ì´ˆê¸°í™”
        try:
            self.oled = OLEDDisplay()
            self.oled_available = True
            self.logger.info("âœ… OLED ë””ìŠ¤í”Œë ˆì´ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"OLED ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.oled_available = False
        
        # PIR ì„¼ì„œ ì´ˆê¸°í™”
        try:
            self.pir = PIRSensor()
            self.pir.set_callback(self.on_pir_motion_detected)
            self.pir_available = True
            self.logger.info("âœ… PIR ì„¼ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"PIR ì„¼ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.pir_available = False
    
    def on_pir_motion_detected(self):
        """PIR ì„¼ì„œ ëª¨ì…˜ ê°ì§€ ì½œë°±"""
        self.logger.info("PIR ëª¨ì…˜ ê°ì§€ - ì¸í¼ëŸ°ìŠ¤ ëª¨ë“œ ì‹œì‘")
        self.system_state = "PIR_DETECTED"
        self.pir_detection_time = time.time()
        
        # RGB LED í°ìƒ‰ìœ¼ë¡œ ë³€ê²½ (PIR ê°ì§€ë¨)
        if self.rgb_available:
            self.rgb.set_color_by_name("white")
        
        # OLED ì—…ë°ì´íŠ¸
        self._update_oled_display()
    
    def _update_oled_display(self):
        """OLED ë””ìŠ¤í”Œë ˆì´ ì—…ë°ì´íŠ¸ (ë¶„ë¥˜ ê²°ê³¼ 3ì´ˆ ìœ ì§€)"""
        if not self.oled_available:
            return
        
        try:
            current_time = time.time()
            pir_status = self.pir.get_status() if self.pir_available else None
            
            lines = [
                "DoorBox v2.0",
                f"Time: {datetime.now().strftime('%H:%M:%S')}",
                f"State: {self.system_state}",
            ]
            
            # PIR ìƒíƒœ í‘œì‹œ
            if pir_status:
                pir_state = "ACTIVE" if pir_status['active'] else "idle"
                lines.append(f"PIR: {pir_state} ({pir_status['count']})")
            else:
                lines.append("PIR: disabled")
            
            # ë¶„ë¥˜ ê²°ê³¼ê°€ ìˆê³  3ì´ˆ ì´ë‚´ì¸ ê²½ìš° ìš°ì„  í‘œì‹œ
            if (self.face_detection_results and 
                self.classification_display_start and 
                current_time - self.classification_display_start < self.classification_display_duration):
                
                emotion = self.face_detection_results.get("emotion", "N/A")
                gender = self.face_detection_results.get("gender", "N/A")
                age_group = self.face_detection_results.get("age_group", "N/A")
                
                lines.append("=== RESULT ===")
                lines.append(f"Emotion: {emotion}")
                lines.append(f"Gender: {gender}")
                lines.append(f"Age: {age_group}")
                
            else:
                # ì¼ë°˜ ìƒíƒœ ì •ë³´ í‘œì‹œ
                if self.system_state == "STANDBY":
                    lines.append("Status: Waiting...")
                    
                elif self.system_state == "PIR_DETECTED":
                    if self.pir_detection_time:
                        elapsed = current_time - self.pir_detection_time
                        lines.append(f"PIR Timer: {elapsed:.1f}s")
                    
                elif self.system_state == "INFERENCE_ACTIVE":
                    if self.green_box_detected:
                        if self.first_green_box_time:
                            time_since_detection = current_time - self.first_green_box_time
                            if self.last_capture_time == 0 and time_since_detection < self.capture_delay:
                                remaining = self.capture_delay - time_since_detection
                                lines.append(f"Capture in {remaining:.1f}s")
                            else:
                                lines.append("Green Box: FOUND")
                    else:
                        lines.append("Green Box: Searching...")
                
                # S3 ì—…ë¡œë“œ ìƒíƒœ
                if self.upload_status["active"]:
                    lines.append(f"Upload: {self.upload_status['queue_size']} pending")
            
            # ìµœëŒ€ 6ì¤„ê¹Œì§€ë§Œ í‘œì‹œ
            self.oled.display_text(lines[:6])
            
        except Exception as e:
            self.logger.error(f"OLED ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
    
    def _pir_monitor_worker(self):
        """PIR ì„¼ì„œ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ (direct GPIOìš©)"""
        while self.running:
            if self.pir_available and GPIO_METHOD == "direct":
                self.pir.check_motion_direct()
            
            # ìƒíƒœë³„ ì²˜ë¦¬
            current_time = time.time()
            
            if self.system_state == "PIR_DETECTED":
                # PIR ê°ì§€ í›„ ì¦‰ì‹œ ì¸í¼ëŸ°ìŠ¤ í™œì„± ëª¨ë“œë¡œ ì „í™˜
                self.system_state = "INFERENCE_ACTIVE"
                self.logger.info("ğŸ”„ ì¸í¼ëŸ°ìŠ¤ í™œì„± ëª¨ë“œë¡œ ì „í™˜")
                
            elif self.system_state == "INFERENCE_ACTIVE":
                # 15ì´ˆ íƒ€ì„ì•„ì›ƒ ì²´í¬
                if self.pir_detection_time and (current_time - self.pir_detection_time) > self.inference_timeout:
                    self.logger.info("â° ì¸í¼ëŸ°ìŠ¤ íƒ€ì„ì•„ì›ƒ - ëŒ€ê¸° ëª¨ë“œë¡œ ë³µê·€")
                    self._return_to_standby()
            
            # OLED ì£¼ê¸°ì  ì—…ë°ì´íŠ¸
            self._update_oled_display()
            
            time.sleep(0.1)  # 100ms ê°„ê²©ìœ¼ë¡œ ì²´í¬
    
    def _return_to_standby(self):
        """ëŒ€ê¸° ëª¨ë“œë¡œ ë³µê·€"""
        self.system_state = "STANDBY"
        self.pir_detection_time = None
        self.green_box_detected = False
        self.face_detection_results = None
        
        # RGB LED ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ë³€ê²½ (ëŒ€ê¸° ìƒíƒœ)
        if self.rgb_available:
            self.rgb.set_color_by_name("red")
        
        # OLED ì—…ë°ì´íŠ¸
        self._update_oled_display()
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(config.LOG_FILE),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê¹… ë ˆë²¨ ì¡°ì •
        logging.getLogger('urllib3').setLevel(logging.WARNING)
        logging.getLogger('boto3').setLevel(logging.WARNING)
        logging.getLogger('botocore').setLevel(logging.WARNING)
        logging.getLogger('PIL').setLevel(logging.WARNING)
    
    def _setup_aws_client(self):
        """AWS S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        self.s3_client = boto3.client(
            's3',
            aws_access_key_id=config.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=config.AWS_SECRET_ACCESS_KEY,
            region_name=config.AWS_REGION
        )
        
        # S3 ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            self.s3_client.head_bucket(Bucket=config.AWS_BUCKET_NAME)
            self.logger.info(f"âœ… S3 ë²„í‚· ì—°ê²° í™•ì¸: {config.AWS_BUCKET_NAME}")
        except Exception as e:
            self.logger.error(f"S3 ë²„í‚· ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def _load_models(self):
        """3ê°€ì§€ ë¶„ë¥˜ ëª¨ë¸ë“¤ ë¡œë“œ"""
        # 1. ê°ì • ë¶„ë¥˜ ëª¨ë¸ (EfficientNet-B0) - 320x320
        self.emotion_model = self._load_emotion_model()
        
        # 2. ì—°ë ¹ëŒ€ ë¶„ë¥˜ ëª¨ë¸ (EfficientNet-B0) - 320x320
        self.age_model = self._load_efficientnet_model(config.AGE_MODEL_PATH, "ì—°ë ¹ëŒ€", num_classes=9)
        
        # 3. ì„±ë³„ ë¶„ë¥˜ ëª¨ë¸ (MobileNetV3-Small) - 320x320
        self.gender_model = self._load_mobilenet_model(config.GENDER_MODEL_PATH, "ì„±ë³„")
        
        # ê³µí†µ ì „ì²˜ë¦¬ (320x320ë¡œ í†µì¼)
        self.common_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((320, 320)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def _load_emotion_model(self):
        """EfficientNet-B0 ëª¨ë¸ ë¡œë“œ (ê°ì • ë¶„ë¥˜ìš©)"""
        try:
            model = efficientnet_b0(pretrained=False)
            model.classifier = nn.Sequential(
                nn.Dropout(0.2),
                nn.Linear(1280, 2)  # alert, non-alert
            )
            
            checkpoint = torch.load(config.EMOTION_MODEL_PATH, map_location='cpu')
            model.load_state_dict(checkpoint)
            model.eval()
            
            self.logger.info("âœ… ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return model
        except Exception as e:
            self.logger.error(f"ê°ì • ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _load_efficientnet_model(self, model_path, model_name, num_classes=9):
        """EfficientNet-B0 ëª¨ë¸ ë¡œë“œ (ì—°ë ¹ëŒ€ ë¶„ë¥˜ìš©)"""
        try:
            if not os.path.exists(model_path):
                self.logger.warning(f"{model_name} ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
                return None
            
            # EfficientNet-B0 ëª¨ë¸ ìƒì„±
            model = efficientnet_b0(pretrained=False)
            model.classifier = nn.Sequential(
                nn.Dropout(0.2),
                nn.Linear(1280, num_classes)
            )
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # state_dict ì¶”ì¶œ
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # ëª¨ë¸ì— ë¡œë“œ
            model.load_state_dict(state_dict, strict=False)
            model.eval()
            
            self.logger.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (EfficientNet-B0, {num_classes}í´ë˜ìŠ¤)")
            return model
            
        except Exception as e:
            self.logger.error(f"{model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _load_mobilenet_model(self, model_path, model_name):
        """MobileNetV3-Small ëª¨ë¸ ë¡œë“œ (ì„±ë³„ ë¶„ë¥˜ìš©)"""
        try:
            if not os.path.exists(model_path):
                self.logger.warning(f"{model_name} ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
                return None
            
            # MobileNetV3-Small ëª¨ë¸ ìƒì„±
            model = mobilenet_v3_small(pretrained=False)
            model.classifier = nn.Sequential(
                nn.Linear(576, 1024),
                nn.Hardswish(),
                nn.Dropout(0.2),
                nn.Linear(1024, 2)  # male, female
            )
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # state_dict ì¶”ì¶œ
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # ëª¨ë¸ì— ë¡œë“œ
            model.load_state_dict(state_dict, strict=False)
            model.eval()
            
            self.logger.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (MobileNetV3-Small)")
            return model
            
        except Exception as e:
            self.logger.error(f"{model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _classify_all_models(self, face_crop):
        """ëª¨ë“  ëª¨ë¸ë¡œ ë¶„ë¥˜ ì‹¤í–‰"""
        results = {
            "emotion": None,
            "emotion_confidence": 0.0,
            "gender": None,
            "gender_confidence": 0.0,
            "age_group": None,
            "age_confidence": 0.0
        }
        
        try:
            # 1. ê°ì • ë¶„ë¥˜ (alert/non-alertë¡œ ë³€ê²½)
            if self.emotion_model is not None:
                emotion, emotion_conf = self._classify_emotion(face_crop)
                results["emotion"] = emotion
                results["emotion_confidence"] = emotion_conf
            
            # 2. ì„±ë³„ ë¶„ë¥˜
            if self.gender_model is not None:
                gender, gender_conf = self._classify_gender(face_crop)
                results["gender"] = gender
                results["gender_confidence"] = gender_conf
            
            # 3. ì—°ë ¹ëŒ€ ë¶„ë¥˜
            if self.age_model is not None:
                age_group, age_conf = self._classify_age(face_crop)
                results["age_group"] = age_group
                results["age_confidence"] = age_conf
            
        except Exception as e:
            self.logger.error(f"ë¶„ë¥˜ ê³¼ì • ì˜¤ë¥˜: {e}")
        
        return results
    
    def _classify_emotion(self, face_crop):
        """ê°ì • ë¶„ë¥˜ (alert/non-alert)"""
        if self.emotion_model is None:
            return "unknown", 0.0
        
        try:
            input_tensor = self.common_transform(face_crop).unsqueeze(0)
            
            with torch.no_grad():
                outputs = self.emotion_model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                emotion_classes = ["alert", "non-alert"]
                emotion = emotion_classes[predicted.item()]
                conf = confidence.item()
                
                return emotion, conf
        except Exception as e:
            self.logger.error(f"ê°ì • ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return "unknown", 0.0

    def _classify_gender(self, face_crop):
        """ì„±ë³„ ë¶„ë¥˜ (0=male, 1=female)"""
        if self.gender_model is None:
            return "unknown", 0.0
        
        try:
            input_tensor = self.common_transform(face_crop).unsqueeze(0)
            
            with torch.no_grad():
                outputs = self.gender_model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                gender_classes = ["male", "female"]  # 0=male, 1=female
                gender = gender_classes[predicted.item()]
                conf = confidence.item()
                
                return gender, conf
        except Exception as e:
            self.logger.error(f"ì„±ë³„ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return "unknown", 0.0
    
    def _classify_age(self, face_crop):
        """ì—°ë ¹ëŒ€ ë¶„ë¥˜ (EfficientNet-B0, 9í´ë˜ìŠ¤: 0s, 10s, 20s, ..., 70s, over80s)"""
        if self.age_model is None:
            return "unknown", 0.0
        
        try:
            input_tensor = self.common_transform(face_crop).unsqueeze(0)
            
            with torch.no_grad():
                outputs = self.age_model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                # 9ê°œ í´ë˜ìŠ¤: 0s, 10s, 20s, 30s, 40s, 50s, 60s, 70s, over80s
                age_classes = ["0s", "10s", "20s", "30s", "40s", "50s", "60s", "70s", "over80s"]
                age_group = age_classes[predicted.item()]
                conf = confidence.item()
                
                return age_group, conf
        except Exception as e:
            self.logger.error(f"ì—°ë ¹ëŒ€ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return "unknown", 0.0
    
    def _init_video_recorder(self):
        """ë¹„ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”"""
        self.frame_buffer = deque(maxlen=30 * config.VIDEO_CLIP_DURATION)  # 30fps * 5ì´ˆ
        self.recording = False
        self.buffer_thread = None
    
    def _start_video_buffering(self):
        """ë¹„ë””ì˜¤ í”„ë ˆì„ ë²„í¼ë§ ì‹œì‘"""
        self.recording = True
        
        def buffer_frames():
            while self.recording and self.running:
                with self.frame_lock:
                    if self.latest_frame is not None:
                        timestamp = time.time()
                        self.frame_buffer.append((self.latest_frame.copy(), timestamp))
                time.sleep(1/30)  # 30fps
        
        self.buffer_thread = threading.Thread(target=buffer_frames, daemon=True)
        self.buffer_thread.start()
    
    def _save_video_clip_improved(self, detection_time, output_path):
        """ê°œì„ ëœ 5ì´ˆ ë¹„ë””ì˜¤ í´ë¦½ ì €ì¥ (MP4 ì½”ë±ë§Œ ì‚¬ìš©)"""
        if not self.frame_buffer:
            self.logger.error("í”„ë ˆì„ ë²„í¼ê°€ ë¹„ì–´ìˆìŒ")
            return False
        
        try:
            # ê°ì§€ ì‹œì  ê¸°ì¤€ìœ¼ë¡œ í”„ë ˆì„ í•„í„°ë§
            clip_frames = []
            start_time = detection_time - config.PRE_BUFFER_DURATION
            end_time = detection_time + config.POST_BUFFER_DURATION
            
            self.logger.debug(f"ë¹„ë””ì˜¤ í´ë¦½ ì‹œê°„ ë²”ìœ„: {start_time:.2f} ~ {end_time:.2f}")
            self.logger.debug(f"í”„ë ˆì„ ë²„í¼ í¬ê¸°: {len(self.frame_buffer)}ê°œ")
            
            for frame, timestamp in list(self.frame_buffer):
                if start_time <= timestamp <= end_time:
                    clip_frames.append(frame)
            
            self.logger.debug(f"í´ë¦½ìš© í”„ë ˆì„ ìˆ˜ì§‘: {len(clip_frames)}ê°œ")
            
            if len(clip_frames) < 10:
                self.logger.warning(f"í´ë¦½ í”„ë ˆì„ ë¶€ì¡±: {len(clip_frames)}ê°œ (ìµœì†Œ 10ê°œ í•„ìš”)")
                return False
            
            # ë””ë ‰í† ë¦¬ í™•ì¸
            output_dir = os.path.dirname(output_path)
            if not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)
                self.logger.info(f"ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")
            
            # ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥ (MP4 ì½”ë±ë§Œ ì‚¬ìš©)
            height, width = clip_frames[0].shape[:2]
            
            try:
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                out = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))
                
                if not out.isOpened():
                    self.logger.error("MP4 VideoWriter ì—´ê¸° ì‹¤íŒ¨")
                    return False
                
                # í”„ë ˆì„ ì“°ê¸°
                for frame in clip_frames:
                    out.write(frame)
                
                out.release()
                
                # íŒŒì¼ ìƒì„± í™•ì¸
                if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                    self.logger.info("ë¹„ë””ì˜¤ ì €ì¥ ì„±ê³µ (MP4)")
                    return True
                else:
                    self.logger.error("MP4 íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                    return False
                    
            except Exception as e:
                self.logger.error(f"MP4 ë¹„ë””ì˜¤ ì €ì¥ ì˜¤ë¥˜: {e}")
                return False
            
        except Exception as e:
            self.logger.error(f"ë¹„ë””ì˜¤ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def _init_s3_uploader(self):
        """S3 ì—…ë¡œë” ì´ˆê¸°í™”"""
        self.upload_queue = []
        self.upload_running = False
        self.upload_thread = None
    
    def _start_s3_uploader(self):
        """S3 ì—…ë¡œë“œ ìŠ¤ë ˆë“œ ì‹œì‘"""
        def upload_worker():
            while self.upload_running:
                # ì—…ë¡œë“œ ìƒíƒœ ì—…ë°ì´íŠ¸
                self.upload_status["queue_size"] = len(self.upload_queue)
                self.upload_status["active"] = len(self.upload_queue) > 0
                
                # S3 ì—…ë¡œë“œ ì‹œ ë³„ë„ì˜ LED ë™ì‘ ì—†ìŒ
                
                self._process_upload_batch()
                time.sleep(config.UPLOAD_INTERVAL)
        
        self.upload_running = True
        self.upload_thread = threading.Thread(target=upload_worker, daemon=True)
        self.upload_thread.start()
        self.logger.info("S3 ì—…ë¡œë“œ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    def _queue_upload_data(self, frame_path, video_path, result_data, capture_timestamp=None):
        """S3 ì—…ë¡œë“œ íì— ë°ì´í„° ì¶”ê°€"""
        # â˜… capture_timestampê°€ ì œê³µë˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ í˜„ì¬ ì‹œê°„
        if capture_timestamp is None:
            seoul_tz = pytz.timezone('Asia/Seoul')
            timestamp = datetime.now(seoul_tz)
        else:
            timestamp = capture_timestamp  # ìº¡ì²˜ ì‹œì ì˜ ì •í™•í•œ ì‹œê°„ ì‚¬ìš©
        
        upload_item = {
            'timestamp': timestamp,
            'frame_path': frame_path,
            'video_path': video_path,
            'result_data': result_data,
            'uploaded': False,
            'retry_count': 0
        }
        
        self.upload_queue.append(upload_item)
        self.logger.info(f"S3 í ì¶”ê°€ - ëŒ€ê¸°ì¤‘: {len(self.upload_queue)}ê°œ")
    
    def _generate_s3_paths(self, timestamp):
        """S3 ê²½ë¡œ ìƒì„± (ì¤‘ë³µ ì œê±°ëœ êµ¬ì¡°)"""
        # timestampê°€ ì´ë¯¸ ì„œìš¸ ì‹œê°„ëŒ€ë©´ ê·¸ëŒ€ë¡œ, ì•„ë‹ˆë©´ ë³€í™˜
        if timestamp.tzinfo is None or timestamp.tzinfo.utcoffset(timestamp) is None:
            # naive datetimeì´ë©´ ì„œìš¸ ì‹œê°„ëŒ€ë¡œ ê°€ì •
            seoul_tz = pytz.timezone('Asia/Seoul')
            dt = seoul_tz.localize(timestamp)
        else:
            # timezone-aware datetimeì´ë©´ ì„œìš¸ ì‹œê°„ëŒ€ë¡œ ë³€í™˜
            seoul_tz = pytz.timezone('Asia/Seoul')
            dt = timestamp.astimezone(seoul_tz)
        
        # S3 ì €ì¥ êµ¬ì¡° (ë²„í‚· ë‚´ë¶€): home-1/cam-1/2025/08/23/...
        folder_name = f"{dt.year:04d}{dt.month:02d}{dt.day:02d}_{dt.hour:02d}{dt.minute:02d}{dt.second:02d}_log"
        
        base_path = f"home-1/cam-1/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}/{folder_name}"
        file_prefix = f"{dt.year:04d}{dt.month:02d}{dt.day:02d}_{dt.hour:02d}{dt.minute:02d}{dt.second:02d}"
        
        # JSONì˜ image_keyëŠ” ì „ì²´ ê²½ë¡œ (doorbox-data í¬í•¨)
        image_key_full_path = f"doorbox-data/home-1/cam-1/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}/{folder_name}/{file_prefix}_frame.jpg"
        
        return {
            'base_path': base_path,
            'frame_key': f"{base_path}/{file_prefix}_frame.jpg",
            'video_key': f"{base_path}/{file_prefix}_clip.mp4",
            'result_key': f"{base_path}/{file_prefix}_result.json",
            'image_key_full_path': image_key_full_path  # JSONìš© ì „ì²´ ê²½ë¡œ
        }
    
    def _upload_file_to_s3(self, local_path, s3_key, content_type):
        """ë‹¨ì¼ íŒŒì¼ S3 ì—…ë¡œë“œ"""
        try:
            with open(local_path, 'rb') as f:
                self.s3_client.put_object(
                    Bucket=config.AWS_BUCKET_NAME,
                    Key=s3_key,
                    Body=f,
                    ContentType=content_type
                )
            return True
        except Exception as e:
            self.logger.error(f"S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {s3_key}, ì˜¤ë¥˜: {e}")
            return False
    
    def _upload_json_to_s3(self, data, s3_key):
        """JSON ë°ì´í„° S3 ì—…ë¡œë“œ"""
        try:
            self.s3_client.put_object(
                Bucket=config.AWS_BUCKET_NAME,
                Key=s3_key,
                Body=json.dumps(data, ensure_ascii=False, indent=2),
                ContentType='application/json'
            )
            return True
        except Exception as e:
            self.logger.error(f"JSON ì—…ë¡œë“œ ì‹¤íŒ¨: {s3_key}, ì˜¤ë¥˜: {e}")
            return False
    
    def _generate_unique_filename(self, base_timestamp_str):
        """ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê³ ìœ  íŒŒì¼ëª… ìƒì„±"""
        with self.filename_lock:
            if base_timestamp_str in self.filename_counter:
                self.filename_counter[base_timestamp_str] += 1
                counter = self.filename_counter[base_timestamp_str]
                return f"{base_timestamp_str}_{counter:02d}"
            else:
                self.filename_counter[base_timestamp_str] = 0
                return base_timestamp_str
    
    def _generate_s3_paths_with_custom_filename(self, timestamp, custom_filename):
        """ì»¤ìŠ¤í…€ íŒŒì¼ëª…ì„ ì‚¬ìš©í•œ S3 ê²½ë¡œ ìƒì„±"""
        # timestampê°€ ì´ë¯¸ ì„œìš¸ ì‹œê°„ëŒ€ë©´ ê·¸ëŒ€ë¡œ, ì•„ë‹ˆë©´ ë³€í™˜
        if timestamp.tzinfo is None or timestamp.tzinfo.utcoffset(timestamp) is None:
            seoul_tz = pytz.timezone('Asia/Seoul')
            dt = seoul_tz.localize(timestamp)
        else:
            seoul_tz = pytz.timezone('Asia/Seoul')
            dt = timestamp.astimezone(seoul_tz)
        
        # custom_filename ì‚¬ìš©
        folder_name = f"{custom_filename}_log"
        
        base_path = f"home-1/cam-1/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}/{folder_name}"
        
        # JSONì˜ image_keyëŠ” ì „ì²´ ê²½ë¡œ (doorbox-data í¬í•¨)
        image_key_full_path = f"doorbox-data/home-1/cam-1/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}/{folder_name}/{custom_filename}_frame.jpg"
        
        return {
            'base_path': base_path,
            'frame_key': f"{base_path}/{custom_filename}_frame.jpg",
            'video_key': f"{base_path}/{custom_filename}_clip.mp4",
            'result_key': f"{base_path}/{custom_filename}_result.json",
            'image_key_full_path': image_key_full_path
        }
    
    def _process_upload_batch(self):
        """ë°°ì¹˜ ì—…ë¡œë“œ ì²˜ë¦¬"""
        if not self.upload_queue:
            # ì—…ë¡œë“œê°€ ì™„ë£Œë˜ë©´ í˜„ì¬ ìƒíƒœì— ë§ëŠ” LED ìƒ‰ìƒìœ¼ë¡œ ë³µê·€
            self.upload_status["active"] = False
            self.upload_status["queue_size"] = 0
            
            if not self.upload_status["active"] and self.rgb_available:
                if self.system_state == "STANDBY":
                    self.rgb.set_color_by_name("red")
                elif self.system_state == "PIR_DETECTED" or self.system_state == "INFERENCE_ACTIVE":
                    self.rgb.set_color_by_name("white")
            return
        
        items_to_process = [item for item in self.upload_queue[:config.UPLOAD_BATCH_SIZE] 
                           if not item['uploaded'] and item['retry_count'] < 3]
        
        for item in items_to_process:
            try:
                s3_paths = self._generate_s3_paths(item['timestamp'])
                # 1. JSON ì—…ë¡œë“œ
                if self._upload_json_to_s3(item['result_data'], s3_paths['result_key']):
                    self.logger.info(f"âœ… JSON: {s3_paths['result_key']}")
                else:
                    item['retry_count'] += 1
                    continue
                
                # 2. í”„ë ˆì„ ì—…ë¡œë“œ
                if os.path.exists(item['frame_path']):
                    if self._upload_file_to_s3(item['frame_path'], s3_paths['frame_key'], 'image/jpeg'):
                        self.logger.info(f"âœ… í”„ë ˆì„: {s3_paths['frame_key']}")
                        os.remove(item['frame_path'])
                    else:
                        item['retry_count'] += 1
                        continue
                
                # 3. ë¹„ë””ì˜¤ ì—…ë¡œë“œ
                if item['video_path'] and os.path.exists(item['video_path']):
                    if self._upload_file_to_s3(item['video_path'], s3_paths['video_key'], 'video/mp4'):
                        self.logger.info(f"âœ… ë¹„ë””ì˜¤: {s3_paths['video_key']}")
                        os.remove(item['video_path'])
                    else:
                        item['retry_count'] += 1
                        continue
                
                item['uploaded'] = True
                self.logger.info(f"ì—…ë¡œë“œ ì™„ë£Œ: {s3_paths['base_path']}")
                
            except Exception as e:
                self.logger.error(f"ì—…ë¡œë“œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                item['retry_count'] += 1
        
        # ì™„ë£Œ/ì‹¤íŒ¨ ì•„ì´í…œ ì œê±°
        self.upload_queue = [item for item in self.upload_queue 
                           if not item['uploaded'] and item['retry_count'] < 3]
        
        if items_to_process:
            self.logger.info(f"ë°°ì¹˜ ì™„ë£Œ - ë‚¨ì€ í: {len(self.upload_queue)}ê°œ")
    
    def _detect_green_boxes(self, frame):
        """ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ê²€ì¶œ"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        lower_green = np.array([40, 50, 50])
        upper_green = np.array([80, 255, 255])
        
        mask = cv2.inRange(hsv, lower_green, upper_green)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        boxes = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 250 * 250:
                x, y, w, h = cv2.boundingRect(contour)
                boxes.append((x, y, w, h))
        
        return boxes
    
    def _expand_bbox(self, bbox, frame_shape, scale=1.5):
        """ë°”ìš´ë”© ë°•ìŠ¤ 1.5ë°° í™•ì¥"""
        x, y, w, h = bbox
        frame_h, frame_w = frame_shape[:2]
        
        center_x = x + w // 2
        center_y = y + h // 2
        
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        new_x = max(0, center_x - new_w // 2)
        new_y = max(0, center_y - new_h // 2)
        
        new_x = min(new_x, frame_w - new_w)
        new_y = min(new_y, frame_h - new_h)
        new_w = min(new_w, frame_w - new_x)
        new_h = min(new_h, frame_h - new_y)
        
        return new_x, new_y, new_w, new_h
    
    def _save_detection_results_direct(self, frame, face_crop, classification_results, capture_timestamp, timestamp_str):
        """ì§ì ‘ ì €ì¥ ë°©ì‹"""
        try:
            # íŒŒì¼ëª… ìƒì„±
            frame_filename = f"{timestamp_str}_frame.jpg"
            video_filename = f"{timestamp_str}_clip.mp4"
            result_filename = f"{timestamp_str}_result.json"
            
            # ì €ì¥ ê²½ë¡œ ìƒì„± (ì ˆëŒ€ê²½ë¡œ ì‚¬ìš©)
            frame_path = os.path.join(config.LOCAL_FRAMES_DIR, frame_filename)
            video_path = os.path.join(config.LOCAL_VIDEOS_DIR, video_filename)
            result_path = os.path.join(config.LOCAL_RESULTS_DIR, result_filename)
            
            # ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸
            os.makedirs(config.LOCAL_FRAMES_DIR, exist_ok=True)
            os.makedirs(config.LOCAL_VIDEOS_DIR, exist_ok=True)
            os.makedirs(config.LOCAL_RESULTS_DIR, exist_ok=True)
            
            # 1. í”„ë ˆì„ ì €ì¥ (ì§ì ‘ ì €ì¥)
            success_frame = cv2.imwrite(frame_path, frame)
            if success_frame and os.path.exists(frame_path):
                file_size = os.path.getsize(frame_path)
                self.logger.info(f"í”„ë ˆì„ ì €ì¥ ì„±ê³µ: {frame_filename} ({file_size} bytes)")
            else:
                self.logger.error(f"í”„ë ˆì„ ì €ì¥ ì‹¤íŒ¨: {frame_filename}")
                return False
            
            # 2. ì–¼êµ´ í¬ë¡­ ì´ë¯¸ì§€ë„ ë³„ë„ ì €ì¥
            face_filename = f"{timestamp_str}_face.jpg"
            face_path = os.path.join(config.LOCAL_FRAMES_DIR, face_filename)
            cv2.imwrite(face_path, face_crop)
            
            # 3. ë¹„ë””ì˜¤ í´ë¦½ ì €ì¥ (í˜„ì¬ ì‹œì  ê¸°ì¤€)
            detection_time = time.time()
            clip_saved = self._save_video_clip_improved(detection_time, video_path)
            
            if clip_saved and os.path.exists(video_path):
                file_size = os.path.getsize(video_path)
                self.logger.info(f"ë¹„ë””ì˜¤ ì €ì¥ ì„±ê³µ: {video_filename} ({file_size} bytes)")
            else:
                self.logger.warning(f"ë¹„ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨: {video_filename}")
                video_path = None
            
            # 4. JSON ê²°ê³¼ ë°ì´í„° ìƒì„±
            s3_paths = self._generate_s3_paths_with_custom_filename(capture_timestamp, timestamp_str)
            result_data = {
                "day": capture_timestamp.strftime("%Y%m%d"),
                "time": capture_timestamp.strftime("%H:%M:%S"),
                "image_key": s3_paths['image_key_full_path'],
                "detection_results": {
                    "emotion": classification_results.get("emotion"),
                    "gender": classification_results.get("gender"),
                    "age_group": classification_results.get("age_group"),
                }
            }
            
            # 5. JSON íŒŒì¼ ì €ì¥
            try:
                with open(result_path, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                
                if os.path.exists(result_path):
                    file_size = os.path.getsize(result_path)
                    self.logger.info(f"ê²°ê³¼ JSON ì €ì¥ ì„±ê³µ: {result_filename} ({file_size} bytes)")
                else:
                    self.logger.error(f"JSON ì €ì¥ ì‹¤íŒ¨: {result_filename}")
            except Exception as e:
                self.logger.error(f"JSON ì €ì¥ ì˜¤ë¥˜: {e}")
            
            # 6. S3 ì—…ë¡œë“œ íì— ì¶”ê°€
            self._queue_upload_data(frame_path, video_path, result_data, capture_timestamp)
            
            # 7. ìƒì„¸ ë¡œê·¸ ì¶œë ¥
            emotion = classification_results.get("emotion", "unknown")
            emotion_conf = classification_results.get("emotion_confidence", 0.0)
            gender = classification_results.get("gender", "unknown")
            gender_conf = classification_results.get("gender_confidence", 0.0)
            age_group = classification_results.get("age_group", "unknown")
            age_conf = classification_results.get("age_confidence", 0.0)
            
            # ê¹”ë”í•œ ë¡œê·¸ ì¶œë ¥
            self.logger.info("=" * 50)
            self.logger.info(f"í”„ë ˆì„ íŒŒì¼: {frame_filename}")
            self.logger.info(f"ìº¡ì²˜ ì‹œê°„: {capture_timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
            self.logger.info("=== ë¶„ë¥˜ ê²°ê³¼ ===")
            self.logger.info(f"   ê°ì •: {emotion} (ì‹ ë¢°ë„: {emotion_conf:.3f})")
            self.logger.info(f"   ì„±ë³„: {gender} (ì‹ ë¢°ë„: {gender_conf:.3f})")
            self.logger.info(f"   ì—°ë ¹ëŒ€: {age_group} (ì‹ ë¢°ë„: {age_conf:.3f})")
            self.logger.info("=" * 50)
            
            return True
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def _rtsp_capture_worker(self):
        """RTSP ìº¡ì²˜ ìŠ¤ë ˆë“œ (ìµœì í™”)"""
        self.cap = cv2.VideoCapture(self.rtsp_url)
        
        if not self.cap.isOpened():
            self.logger.error("RTSP ì—°ê²° ì‹¤íŒ¨")
            return
        
        # RTSP ìŠ¤íŠ¸ë¦¼ ìµœì í™” ì„¤ì •
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ í¬ê¸° ìµœì†Œí™” (ì§€ì—° ì‹œê°„ ê°ì†Œ)
        self.cap.set(cv2.CAP_PROP_FPS, 30)        # FPS ì„¤ì •
        
        # ì´ˆê¸° ëª‡ í”„ë ˆì„ì€ ë²„ë¦¼ (ì—°ê²° ì•ˆì •í™”)
        for _ in range(5):
            self.cap.read()
        
        self.logger.info("RTSP ìŠ¤íŠ¸ë¦¼ ì‹œì‘ (ìµœì í™”ë¨)")
        
        frame_count = 0
        while self.running:
            ret, frame = self.cap.read()
            if ret:
                with self.frame_lock:
                    self.latest_frame = frame.copy()
                frame_count += 1
                
            else:
                self.logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                time.sleep(0.01)  # ì§§ì€ ëŒ€ê¸°
            
            # CPU ì‚¬ìš©ë¥  ìµœì í™”
            time.sleep(0.001)  # 1ms ëŒ€ê¸° (ê¸°ì¡´ 0.1ì´ˆì—ì„œ ë‹¨ì¶•)
        
        self.cap.release()
        self.logger.info("RTSP ìº¡ì²˜ ì¢…ë£Œ")
    
    def _serial_reader_worker(self):
        """ì‹œë¦¬ì–¼ í†µì‹  ìŠ¤ë ˆë“œ (ìµœì í™”)"""
        try:
            self.ser = serial.Serial(self.serial_port, self.serial_baudrate, timeout=0.1)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
            self.logger.info(f"ì‹œë¦¬ì–¼ ì—°ê²° ì„±ê³µ: {self.serial_port}")
        except Exception as e:
            self.logger.error(f"ì‹œë¦¬ì–¼ ì—°ê²° ì‹¤íŒ¨: {e}")
            return
        
        while self.running:
            try:
                if self.ser.in_waiting > 0:
                    line = self.ser.readline().decode('utf-8').strip()
                    if line:
                        # PIR ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œëŠ” ì‹œë¦¬ì–¼ ë°ì´í„° ëŒ€ì‹  í”„ë ˆì„ ê¸°ë°˜ ì²˜ë¦¬ë§Œ ìˆ˜í–‰
                        # YOLO ê²°ê³¼ëŠ” ì°¸ê³ ë§Œ í•˜ê³ , ì‹¤ì œ ì²˜ë¦¬ëŠ” PIR íŠ¸ë¦¬ê±° ê¸°ë°˜ìœ¼ë¡œ ìˆ˜í–‰
                        if "[print_yolo_result]" in line and "[AI coordinate]" in line:
                            # ë¡œê·¸ë§Œ ì¶œë ¥í•˜ê³  ë³„ë„ ì²˜ë¦¬ ì•ˆí•¨
                            self.logger.debug(f"YOLO ê²°ê³¼ ìˆ˜ì‹ : {line}")
                
                time.sleep(0.001)  # 1ms ëŒ€ê¸° (ê¸°ì¡´ 0.1ì´ˆì—ì„œ ë‹¨ì¶•)
                
            except Exception as e:
                self.logger.error(f"ì‹œë¦¬ì–¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                time.sleep(0.1)
        
        if self.ser:
            self.ser.close()
        self.logger.info("ì‹œë¦¬ì–¼ í†µì‹  ì¢…ë£Œ")
    
    def _process_inference_frame(self):
        """PIR ê°ì§€ í›„ ì¸í¼ëŸ°ìŠ¤ í”„ë ˆì„ ì²˜ë¦¬ (ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ê¸°ë°˜ ìº¡ì²˜ íƒ€ì´ë° ê°œì„ )"""
        if self.system_state != "INFERENCE_ACTIVE":
            return
        
        current_time = time.time()
        
        # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬
        if current_time - self.pir_detection_time > config.DETECTION_TIMEOUT:
            self._return_to_standby()
            return
        
        # ìº¡ì²˜ ì‹œì ì˜ ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        seoul_tz = pytz.timezone('Asia/Seoul')
        capture_timestamp = datetime.now(seoul_tz)
        
        with self.frame_lock:
            if self.latest_frame is None:
                self.logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ì´ ì—†ìŒ")
                return
            current_frame = self.latest_frame.copy()
        
        # ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ê²€ì¶œ
        boxes = self._detect_green_boxes(current_frame)
        
        if not boxes:
            # ì´ˆë¡ìƒ‰ ë°•ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒíƒœ ì´ˆê¸°í™”
            if self.green_box_detected:
                self.green_box_detected = False
                self.first_green_box_time = None
                self.logger.debug("ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ì‚¬ë¼ì§ - ìƒíƒœ ì´ˆê¸°í™”")
            return
        
        # ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ê°ì§€ë¨
        if not self.green_box_detected:
            # ì²« ë²ˆì§¸ ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ê°ì§€
            self.green_box_detected = True
            self.first_green_box_time = current_time
            self.logger.info("ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ì²« ê°ì§€ - 2ì´ˆ í›„ ìº¡ì²˜ ì‹œì‘ ì˜ˆì •")
            
            # RGB LED ë³´ë¼ìƒ‰ìœ¼ë¡œ ì ë©¸
            if self.rgb_available:
                self.rgb.blink_purple(times=3, interval=0.3)
                self.rgb.set_color_by_name("white")
            
            return
        
        # ì´ˆë¡ìƒ‰ ë°•ìŠ¤ê°€ ì§€ì†ì ìœ¼ë¡œ ê°ì§€ë˜ëŠ” ìƒíƒœì—ì„œ ìº¡ì²˜ íƒ€ì´ë° ê²°ì •
        time_since_first_detection = current_time - self.first_green_box_time
        
        should_capture = False
        
        if self.last_capture_time == 0:
            # ì²« ë²ˆì§¸ ìº¡ì²˜: ì²« ê°ì§€ í›„ 2ì´ˆ ì§€ì—°
            if time_since_first_detection >= self.capture_delay:
                should_capture = True
        else:
            # í›„ì† ìº¡ì²˜: ë§ˆì§€ë§‰ ìº¡ì²˜ë¡œë¶€í„° 5ì´ˆ ê°„ê²©
            if current_time - self.last_capture_time >= self.capture_interval:
                should_capture = True
        
        if not should_capture:
            return
        
        # ìº¡ì²˜ ë° ë¶„ë¥˜ ì‹¤í–‰
        self.logger.info("ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ì§€ì† ê°ì§€ - ì–¼êµ´ ë¶„ë¥˜ ì‹¤í–‰")
        
        # ê°€ì¥ í° ë°•ìŠ¤ ì„ íƒ
        largest_box = max(boxes, key=lambda box: box[2] * box[3])
        
        # ë°•ìŠ¤ í™•ì¥
        expanded_box = self._expand_bbox(largest_box, current_frame.shape)
        x, y, w, h = expanded_box
        
        # ì–¼êµ´ ì˜ì—­ í¬ë¡­
        face_crop = current_frame[y:y+h, x:x+w]
        
        if face_crop.size == 0:
            self.logger.warning("í¬ë¡­ëœ ì–¼êµ´ ì˜ì—­ì´ ë¹„ì–´ìˆìŒ")
            return
        
        # ê³ ìœ  íŒŒì¼ëª… ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        base_timestamp_str = capture_timestamp.strftime("%Y%m%d_%H%M%S")
        unique_timestamp_str = self._generate_unique_filename(base_timestamp_str)
        
        # ëª¨ë“  ëª¨ë¸ë¡œ ë¶„ë¥˜ ì‹¤í–‰
        classification_results = self._classify_all_models(face_crop)
        
        # ê²°ê³¼ ì €ì¥ (ì§ì ‘ ì €ì¥ ë°©ì‹ ì‚¬ìš©)
        success = self._save_detection_results_direct(
            current_frame, 
            face_crop,
            classification_results, 
            capture_timestamp, 
            unique_timestamp_str
        )
        
        if success:
            self.last_capture_time = current_time
            # OLED í‘œì‹œìš© ê²°ê³¼ ì €ì¥ ë° í‘œì‹œ ì‹œì‘ ì‹œê°„ ì„¤ì •
            self.face_detection_results = classification_results
            self.classification_display_start = current_time
    
    def _inference_loop_worker(self):
        """ì¸í¼ëŸ°ìŠ¤ ë£¨í”„ ìŠ¤ë ˆë“œ"""
        while self.running:
            if self.system_state == "INFERENCE_ACTIVE":
                try:
                    self._process_inference_frame()
                    time.sleep(1.0)  # 1ì´ˆ ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ ì²˜ë¦¬
                except Exception as e:
                    self.logger.error(f"ì¸í¼ëŸ°ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            else:
                time.sleep(0.1)  # ë¹„í™œì„± ìƒíƒœì—ì„œëŠ” ì§§ì€ ëŒ€ê¸°
    
    # ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    def search_logs_by_filename(self, filename_pattern):
        """íŒŒì¼ëª… íŒ¨í„´ìœ¼ë¡œ ë¡œê·¸ ê²€ìƒ‰ (ë””ë²„ê¹…ìš©)"""
        log_file = config.LOG_FILE
        results = []
        
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
            in_classification_block = False
            current_block = []
            
            for line in lines:
                if filename_pattern in line and "í”„ë ˆì„ íŒŒì¼:" in line:
                    in_classification_block = True
                    current_block = [line.strip()]
                elif in_classification_block:
                    current_block.append(line.strip())
                    if "=" * 50 in line:  # ë¸”ë¡ ì¢…ë£Œ
                        results.append('\n'.join(current_block))
                        in_classification_block = False
                        current_block = []
        
        except Exception as e:
            self.logger.error(f"ë¡œê·¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return results
    
    def debug_classification_by_file(self, frame_filename):
        """íŠ¹ì • í”„ë ˆì„ íŒŒì¼ì˜ ë¶„ë¥˜ ê²°ê³¼ ì¡°íšŒ"""
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
        base_name = frame_filename.replace('_frame.jpg', '').replace('.jpg', '')
        
        # ë¡œê·¸ì—ì„œ í•´ë‹¹ íŒŒì¼ì˜ ë¶„ë¥˜ ê²°ê³¼ ê²€ìƒ‰
        results = self.search_logs_by_filename(base_name)
        
        if results:
            print(f"\nğŸ” {frame_filename}ì˜ ë¶„ë¥˜ ê²°ê³¼:")
            for result in results:
                print(result)
        else:
            print(f"âŒ {frame_filename}ì— ëŒ€í•œ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return results
    
    def start(self):
        """ì‹œìŠ¤í…œ ì‹œì‘"""
        self.running = True
        
        # í•˜ë“œì›¨ì–´ ìƒíƒœ í‘œì‹œ
        self.logger.info("=" * 60)
        self.logger.info("ğŸšª DoorBox PIR í†µí•© ì‹œìŠ¤í…œ")
        self.logger.info("=" * 60)
        self.logger.info(f"ğŸ’¡ RGB LED: {'í™œì„±' if self.rgb_available else 'ë¹„í™œì„±'}")
        self.logger.info(f"ğŸ“º OLED Display: {'í™œì„±' if self.oled_available else 'ë¹„í™œì„±'}")
        self.logger.info(f"ğŸš¶ PIR Sensor: {'í™œì„±' if self.pir_available else 'ë¹„í™œì„±'}")
        self.logger.info(f"ğŸ”§ GPIO Method: {GPIO_METHOD}")
        self.logger.info("=" * 60)
        
        # ì‹œìŠ¤í…œ ì´ˆê¸° ìƒíƒœ ì„¤ì •
        self._return_to_standby()
        
        # ë¹„ë””ì˜¤ ë²„í¼ë§ ì‹œì‘
        self._start_video_buffering()
        
        # S3 ì—…ë¡œë” ì‹œì‘
        self._start_s3_uploader()
        
        # RTSP ìº¡ì²˜ ìŠ¤ë ˆë“œ ì‹œì‘
        self.rtsp_thread = threading.Thread(target=self._rtsp_capture_worker, daemon=True)
        self.rtsp_thread.start()
        
        # ì‹œë¦¬ì–¼ ë¦¬ë” ìŠ¤ë ˆë“œ ì‹œì‘
        self.serial_thread = threading.Thread(target=self._serial_reader_worker, daemon=True)
        self.serial_thread.start()
        
        # PIR ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘ (direct GPIOìš©)
        self.pir_monitor_thread = threading.Thread(target=self._pir_monitor_worker, daemon=True)
        self.pir_monitor_thread.start()
        
        # ì¸í¼ëŸ°ìŠ¤ ë£¨í”„ ìŠ¤ë ˆë“œ ì‹œì‘
        self.inference_thread = threading.Thread(target=self._inference_loop_worker, daemon=True)
        self.inference_thread.start()
        
        self.logger.info("âœ… DoorBox PIR í†µí•© ì‹œìŠ¤í…œ ì‹œì‘ë¨")
        
        # ë©”ì¸ ë£¨í”„
        try:
            while self.running:
                # ì£¼ê¸°ì ìœ¼ë¡œ OLED ì—…ë°ì´íŠ¸
                self._update_oled_display()
                time.sleep(1)
        except KeyboardInterrupt:
            self.logger.info("í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ ê°ì§€")
            self.stop()
    
    def stop(self):
        """ì‹œìŠ¤í…œ ì¢…ë£Œ"""
        self.logger.info("ğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
        
        self.running = False
        
        # ë¹„ë””ì˜¤ ë ˆì½”ë” ì¢…ë£Œ
        self.recording = False
        if self.buffer_thread:
            self.buffer_thread.join(timeout=2)
        
        # S3 ì—…ë¡œë” ì¢…ë£Œ (ë‚¨ì€ í ì²˜ë¦¬)
        if self.upload_queue:
            self.logger.info("ë‚¨ì€ ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘...")
            self._process_upload_batch()
        
        self.upload_running = False
        if self.upload_thread:
            self.upload_thread.join(timeout=5)
        
        # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if self.rtsp_thread:
            self.rtsp_thread.join(timeout=3)
        if self.serial_thread:
            self.serial_thread.join(timeout=3)
        if self.pir_monitor_thread:
            self.pir_monitor_thread.join(timeout=3)
        if hasattr(self, 'inference_thread') and self.inference_thread:
            self.inference_thread.join(timeout=3)
        
        # í•˜ë“œì›¨ì–´ ì •ë¦¬
        if self.rgb_available:
            self.rgb.cleanup()
        
        if self.oled_available:
            self.oled.clear()
        
        if self.pir_available:
            self.pir.cleanup()
        
        self.logger.info("âœ… DoorBox PIR í†µí•© ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸšª DoorBox PIR í†µí•© ì‹œìŠ¤í…œ")
    print("í•˜ë“œì›¨ì–´ ì—°ê²°:")
    print("  RGB LED: R=Pin12, G=Pin16, B=Pin18, GND=Pin9")
    print("  OLED: SDA=Pin3, SCL=Pin5, VCC=Pin1, GND=Pin6") 
    print("  PIR: VCC=Pin4, OUT=Pin8, GND=Pin9")
    print("  CatchCAM: USB + UART")
    print()
    
    doorbox = None
    
    try:
        doorbox = DoorBoxInferenceSystem()
        doorbox.start()
    except Exception as e:
        logging.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    finally:
        if doorbox:
            doorbox.stop()

if __name__ == "__main__":
    main()
