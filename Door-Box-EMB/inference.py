import cv2
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.models import efficientnet_b0, mobilenet_v3_small
import timm
import serial
import threading
import time
import json
import os
import boto3
from datetime import datetime, timezone
import pytz  # ì‹œê°„ëŒ€ ì„¤ì •ìš©
from collections import deque
import logging
from botocore.exceptions import ClientError
import warnings

# Warning ë©”ì‹œì§€ ì™„ì „íˆ ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore")
import torchvision  

# ì„¤ì • íŒŒì¼ import
import config

class DoorBoxInferenceSystem:
    def __init__(self):
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        config.create_directories()
        
        # AWS S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        self._setup_aws_client()
        
        # ê¸°ë³¸ ì„¤ì •
        self.rtsp_url = config.RTSP_URL
        self.serial_port = config.SERIAL_PORT
        self.serial_baudrate = config.SERIAL_BAUDRATE
        self.device_id = config.DEVICE_ID
        
        # êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
        self.cap = None
        self.ser = None
        self.running = False
        
        # ëª¨ë¸ë“¤ ë¡œë“œ
        self._load_all_models()
        
        # ë¹„ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”
        self._init_video_recorder()
        
        # S3 ì—…ë¡œë” ì´ˆê¸°í™”
        self._init_s3_uploader()
        
        # ìŠ¤ë ˆë“œ ê´€ë¦¬
        self.rtsp_thread = None
        self.serial_thread = None
        
        # í”„ë ˆì„ ë²„í¼
        self.latest_frame = None
        self.frame_lock = threading.Lock()
        
        # ê°ì§€ ìƒíƒœ ê´€ë¦¬
        self.detection_active = False
        self.first_detection_time = None
        self.last_capture_time = None
        self.detection_session_id = None
        
        # â˜… ìº¡ì²˜ ìƒíƒœ ê´€ë¦¬ ê°•í™”
        self.capture_in_progress = False  # ìº¡ì²˜ ì§„í–‰ ì¤‘ í”Œë˜ê·¸
        self.capture_lock = threading.Lock()  # ìº¡ì²˜ ë™ê¸°í™”ìš©
        self.last_successful_capture_time = 0  # ë§ˆì§€ë§‰ ì„±ê³µí•œ ìº¡ì²˜ ì‹œê°„
        self.capture_timer = None  # í˜„ì¬ í™œì„±í™”ëœ íƒ€ì´ë¨¸
        self.pending_captures = 0  # ëŒ€ê¸° ì¤‘ì¸ ìº¡ì²˜ ìˆ˜
        
        # â˜… íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ì¹´ìš´í„°
        self.filename_counter = {}  # {base_filename: count}
        self.filename_lock = threading.Lock()
        
        self.logger.info("DoorBox ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(config.LOG_FILE),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê¹… ë ˆë²¨ ì¡°ì •
        logging.getLogger('urllib3').setLevel(logging.WARNING)
        logging.getLogger('boto3').setLevel(logging.WARNING)
        logging.getLogger('botocore').setLevel(logging.WARNING)
        logging.getLogger('PIL').setLevel(logging.WARNING)
    
    def _setup_aws_client(self):
        """AWS S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        self.s3_client = boto3.client(
            's3',
            aws_access_key_id=config.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=config.AWS_SECRET_ACCESS_KEY,
            region_name=config.AWS_REGION
        )
        
        # S3 ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            self.s3_client.head_bucket(Bucket=config.AWS_BUCKET_NAME)
            self.logger.info(f"âœ… S3 ë²„í‚· ì—°ê²° í™•ì¸: {config.AWS_BUCKET_NAME}")
        except Exception as e:
            self.logger.error(f"S3 ë²„í‚· ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def _load_all_models(self):
        """ëª¨ë“  ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ"""
        # 1. ê°ì • ë¶„ë¥˜ ëª¨ë¸ (EfficientNet-B0) - 320x320
        self.emotion_model = self._load_emotion_model()
        
        # 2. ì•…ì„¸ì„œë¦¬(ë§ˆìŠ¤í¬) ë¶„ë¥˜ ëª¨ë¸ (GhostNet) - 320x320
        self.accessory_model = self._load_ghostnet_model(config.ACCESSORY_MODEL_PATH, "ì•…ì„¸ì„œë¦¬")
        
        # 3. ì—°ë ¹ëŒ€ ë¶„ë¥˜ ëª¨ë¸ (EfficientNet-B0) - 320x320
        self.age_model = self._load_efficientnet_model(config.AGE_MODEL_PATH, "ì—°ë ¹ëŒ€", num_classes=9)
        
        # 4. ì„±ë³„ ë¶„ë¥˜ ëª¨ë¸ (MobileNetV3-Small) - 320x320
        self.gender_model = self._load_mobilenet_model(config.GENDER_MODEL_PATH, "ì„±ë³„")
        
        # ê³µí†µ ì „ì²˜ë¦¬ (320x320ë¡œ í†µì¼)
        self.common_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((320, 320)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def _load_emotion_model(self):
        """ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ (EfficientNet-B0)"""
        try:
            model = efficientnet_b0(pretrained=False)
            model.classifier = nn.Sequential(
                nn.Dropout(0.2),
                nn.Linear(1280, 2)  # alert, non-alert
            )
            
            checkpoint = torch.load(config.EMOTION_MODEL_PATH, map_location='cpu')
            model.load_state_dict(checkpoint)
            model.eval()
            
            self.logger.info("âœ… ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return model
        except Exception as e:
            self.logger.error(f"ê°ì • ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _load_ghostnet_model(self, model_path, model_name):
        """GhostNet ëª¨ë¸ ë¡œë“œ (ì•…ì„¸ì„œë¦¬/ë§ˆìŠ¤í¬ ë¶„ë¥˜ìš©)"""
        try:
            if not os.path.exists(model_path):
                self.logger.warning(f"{model_name} ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
                return None
            
            # ì²´í¬í¬ì¸íŠ¸ ë¨¼ì € ë¡œë“œí•´ì„œ êµ¬ì¡° í™•ì¸
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # state_dict ì¶”ì¶œ
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # classifier í¬ê¸° í™•ì¸
            classifier_weight_shape = None
            for key in state_dict.keys():
                if 'classifier.weight' in key:
                    classifier_weight_shape = state_dict[key].shape
                    break
            
            if classifier_weight_shape is not None:
                num_classes, feature_dim = classifier_weight_shape
                self.logger.info(f"{model_name} ëª¨ë¸ êµ¬ì¡°: {num_classes}í´ë˜ìŠ¤, {feature_dim}ì°¨ì›")
                
                # ì»¤ìŠ¤í…€ GhostNet ëª¨ë¸ ìƒì„± (feature_dimì— ë§ì¶°)
                class CustomGhostNet(nn.Module):
                    def __init__(self, num_classes=2, feature_dim=960):
                        super().__init__()
                        # GhostNet backbone (feature extractor only)
                        self.backbone = timm.create_model('ghostnet_100', pretrained=False, num_classes=0)
                        
                        # backbone ì¶œë ¥ ì°¨ì› í™•ì¸ ë° ì¡°ì •
                        backbone_dim = self.backbone.num_features
                        
                        # feature_dimì— ë§ì¶° projection layer ì¶”ê°€
                        if backbone_dim != feature_dim:
                            self.projection = nn.Linear(backbone_dim, feature_dim)
                        else:
                            self.projection = nn.Identity()
                        
                        # classifier
                        self.classifier = nn.Linear(feature_dim, num_classes)
                    
                    def forward(self, x):
                        features = self.backbone(x)
                        features = self.projection(features)
                        return self.classifier(features)
                
                model = CustomGhostNet(num_classes, feature_dim)
                
            else:
                # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
                model = timm.create_model('ghostnet_100', pretrained=False, num_classes=2)
            
            # ëª¨ë¸ì— ë¡œë“œ (strict=Falseë¡œ í˜¸í™˜ì„± í™•ë³´)
            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
            
            if missing_keys:
                self.logger.warning(f"ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
            if unexpected_keys:
                self.logger.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
            
            model.eval()
            
            self.logger.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Custom GhostNet)")
            return model
            
        except Exception as e:
            self.logger.error(f"{model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _load_efficientnet_model(self, model_path, model_name, num_classes=9):
        """EfficientNet-B0 ëª¨ë¸ ë¡œë“œ (ì—°ë ¹ëŒ€ ë¶„ë¥˜ìš©)"""
        try:
            if not os.path.exists(model_path):
                self.logger.warning(f"{model_name} ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
                return None
            
            # EfficientNet-B0 ëª¨ë¸ ìƒì„±
            model = efficientnet_b0(pretrained=False)
            model.classifier = nn.Sequential(
                nn.Dropout(0.2),
                nn.Linear(1280, num_classes)
            )
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # state_dict ì¶”ì¶œ
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # ëª¨ë¸ì— ë¡œë“œ
            model.load_state_dict(state_dict, strict=False)
            model.eval()
            
            self.logger.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (EfficientNet-B0, {num_classes}í´ë˜ìŠ¤)")
            return model
            
        except Exception as e:
            self.logger.error(f"{model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _load_mobilenet_model(self, model_path, model_name):
        """MobileNetV3-Small ëª¨ë¸ ë¡œë“œ (ì„±ë³„ ë¶„ë¥˜ìš©)"""
        try:
            if not os.path.exists(model_path):
                self.logger.warning(f"{model_name} ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
                return None
            
            # MobileNetV3-Small ëª¨ë¸ ìƒì„±
            model = mobilenet_v3_small(pretrained=False)
            model.classifier = nn.Sequential(
                nn.Linear(576, 1024),
                nn.Hardswish(),
                nn.Dropout(0.2),
                nn.Linear(1024, 2)  # male, female
            )
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # state_dict ì¶”ì¶œ
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # ëª¨ë¸ì— ë¡œë“œ
            model.load_state_dict(state_dict, strict=False)
            model.eval()
            
            self.logger.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (MobileNetV3-Small)")
            return model
            
        except Exception as e:
            self.logger.error(f"{model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _classify_all_models(self, face_crop):
        """ëª¨ë“  ëª¨ë¸ë¡œ ë¶„ë¥˜ ì‹¤í–‰"""
        results = {
            "emotion": None,
            "emotion_confidence": 0.0,
            "accessory": None,  # has_mask â†’ accessoryë¡œ ë³€ê²½
            "gender": None,
            "gender_confidence": 0.0,
            "age_group": None,
            "age_confidence": 0.0
        }
        
        try:
            # 1. ì•…ì„¸ì„œë¦¬(ë§ˆìŠ¤í¬) ë¶„ë¥˜ - ìš°ì„  ì‹¤í–‰ (confidence ì œì™¸)
            if self.accessory_model is not None:
                accessory_result = self._classify_accessory(face_crop)
                results["accessory"] = accessory_result
                
                # ë§ˆìŠ¤í¬ ì°©ìš©ì‹œ ë‹¤ë¥¸ ë¶„ë¥˜ ê±´ë„ˆë›°ê¸°
                if accessory_result:
                    self.logger.info("ë§ˆìŠ¤í¬ ì°©ìš© ê°ì§€ - ë‹¤ë¥¸ ë¶„ë¥˜ ìƒëµ")
                    return results
            
            # 2. ê°ì • ë¶„ë¥˜ (alert/non-alertë¡œ ë³€ê²½)
            if self.emotion_model is not None:
                emotion, emotion_conf = self._classify_emotion(face_crop)
                results["emotion"] = emotion
                results["emotion_confidence"] = emotion_conf
            
            # 3. ì„±ë³„ ë¶„ë¥˜
            if self.gender_model is not None:
                gender, gender_conf = self._classify_gender(face_crop)
                results["gender"] = gender
                results["gender_confidence"] = gender_conf
            
            # 4. ì—°ë ¹ëŒ€ ë¶„ë¥˜
            if self.age_model is not None:
                age_group, age_conf = self._classify_age(face_crop)
                results["age_group"] = age_group
                results["age_confidence"] = age_conf
            
        except Exception as e:
            self.logger.error(f"ë¶„ë¥˜ ê³¼ì • ì˜¤ë¥˜: {e}")
        
        return results
    
    def _classify_emotion(self, face_crop):
        """ê°ì • ë¶„ë¥˜ (alert/non-alert)"""
        if self.emotion_model is None:
            return "unknown", 0.0
        
        try:
            input_tensor = self.common_transform(face_crop).unsqueeze(0)
            
            with torch.no_grad():
                outputs = self.emotion_model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                emotion_classes = ["alert", "non-alert"]  # negative â†’ alert, non-negative â†’ non-alert
                emotion = emotion_classes[predicted.item()]
                conf = confidence.item()
                
                return emotion, conf
        except Exception as e:
            self.logger.error(f"ê°ì • ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return "unknown", 0.0
    
    def _classify_accessory(self, face_crop):
        """ì•…ì„¸ì„œë¦¬(ë§ˆìŠ¤í¬) ë¶„ë¥˜ - confidence ì œì™¸"""
        if self.accessory_model is None:
            return None
        
        try:
            input_tensor = self.common_transform(face_crop).unsqueeze(0)
            
            with torch.no_grad():
                # backboneìœ¼ë¡œ feature ì¶”ì¶œ
                if hasattr(self.accessory_model, 'backbone'):
                    features = self.accessory_model.backbone(input_tensor)
                    
                    # ì°¨ì› ë§ì¶¤: 1280 â†’ 960
                    if features.shape[1] == 1280:
                        # ê°„ë‹¨í•œ ì°¨ì› ì¶•ì†Œ (ì²« 960ê°œ ì°¨ì›ë§Œ ì‚¬ìš©)
                        features = features[:, :960]
                    
                    # classifier ì ìš©
                    outputs = self.accessory_model.classifier(features)
                else:
                    # ì¼ë°˜ì ì¸ forward
                    outputs = self.accessory_model(input_tensor)
                
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                # 0: ë§ˆìŠ¤í¬ ì—†ìŒ, 1: ë§ˆìŠ¤í¬ ìˆìŒ
                has_mask = bool(predicted.item())
                conf = confidence.item()
                
                # ì„ê³„ê°’ ì ìš© (ì‹ ë¢°ë„ê°€ 0.7 ì´ìƒì¼ ë•Œë§Œ ë§ˆìŠ¤í¬ ì°©ìš©ìœ¼ë¡œ íŒë‹¨)
                if conf < 0.7:
                    has_mask = False
                
                return has_mask  # confidence ì œì™¸í•˜ê³  booleanë§Œ ë°˜í™˜
        except Exception as e:
            self.logger.error(f"ì•…ì„¸ì„œë¦¬ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return False
    
    def _classify_gender(self, face_crop):
        """ì„±ë³„ ë¶„ë¥˜ (0=male, 1=female)"""
        if self.gender_model is None:
            return "unknown", 0.0
        
        try:
            input_tensor = self.common_transform(face_crop).unsqueeze(0)
            
            with torch.no_grad():
                outputs = self.gender_model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                gender_classes = ["male", "female"]  # 0=male, 1=female
                gender = gender_classes[predicted.item()]
                conf = confidence.item()
                
                return gender, conf
        except Exception as e:
            self.logger.error(f"ì„±ë³„ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return "unknown", 0.0
    
    def _classify_age(self, face_crop):
        """ì—°ë ¹ëŒ€ ë¶„ë¥˜ (EfficientNet-B0, 9í´ë˜ìŠ¤: 0s, 10s, 20s, ..., 70s, over80s)"""
        if self.age_model is None:
            return "unknown", 0.0
        
        try:
            input_tensor = self.common_transform(face_crop).unsqueeze(0)
            
            with torch.no_grad():
                outputs = self.age_model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                # 9ê°œ í´ë˜ìŠ¤: 0s, 10s, 20s, 30s, 40s, 50s, 60s, 70s, over80s
                age_classes = ["0s", "10s", "20s", "30s", "40s", "50s", "60s", "70s", "over80s"]
                age_group = age_classes[predicted.item()]
                conf = confidence.item()
                
                return age_group, conf
        except Exception as e:
            self.logger.error(f"ì—°ë ¹ëŒ€ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return "unknown", 0.0
    
    def _init_video_recorder(self):
        """ë¹„ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”"""
        self.frame_buffer = deque(maxlen=30 * config.VIDEO_CLIP_DURATION)  # 30fps * 5ì´ˆ
        self.recording = False
        self.buffer_thread = None
    
    def _start_video_buffering(self):
        """ë¹„ë””ì˜¤ í”„ë ˆì„ ë²„í¼ë§ ì‹œì‘"""
        self.recording = True
        
        def buffer_frames():
            while self.recording and self.running:
                with self.frame_lock:
                    if self.latest_frame is not None:
                        timestamp = time.time()
                        self.frame_buffer.append((self.latest_frame.copy(), timestamp))
                time.sleep(1/30)  # 30fps
        
        self.buffer_thread = threading.Thread(target=buffer_frames, daemon=True)
        self.buffer_thread.start()
    
    def _save_video_clip(self, detection_time, output_path):
        """5ì´ˆ ë¹„ë””ì˜¤ í´ë¦½ ì €ì¥"""
        if not self.frame_buffer:
            return False
        
        try:
            # ê°ì§€ ì‹œì  ê¸°ì¤€ìœ¼ë¡œ í”„ë ˆì„ í•„í„°ë§
            clip_frames = []
            start_time = detection_time - config.PRE_BUFFER_DURATION
            end_time = detection_time + config.POST_BUFFER_DURATION
            
            for frame, timestamp in self.frame_buffer:
                if start_time <= timestamp <= end_time:
                    clip_frames.append(frame)
            
            if len(clip_frames) < 10:
                return False
            
            # ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥
            height, width = clip_frames[0].shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))
            
            for frame in clip_frames:
                out.write(frame)
            
            out.release()
            return True
            
        except Exception as e:
            self.logger.error(f"ë¹„ë””ì˜¤ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def _init_s3_uploader(self):
        """S3 ì—…ë¡œë” ì´ˆê¸°í™”"""
        self.upload_queue = []
        self.upload_running = False
        self.upload_thread = None
    
    def _start_s3_uploader(self):
        """S3 ì—…ë¡œë“œ ìŠ¤ë ˆë“œ ì‹œì‘"""
        def upload_worker():
            while self.upload_running:
                self._process_upload_batch()
                time.sleep(config.UPLOAD_INTERVAL)
        
        self.upload_running = True
        self.upload_thread = threading.Thread(target=upload_worker, daemon=True)
        self.upload_thread.start()
        self.logger.info("S3 ì—…ë¡œë“œ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    def _queue_upload_data(self, frame_path, video_path, result_data, capture_timestamp=None):
        """S3 ì—…ë¡œë“œ íì— ë°ì´í„° ì¶”ê°€"""
        # â˜… capture_timestampê°€ ì œê³µë˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ í˜„ì¬ ì‹œê°„
        if capture_timestamp is None:
            seoul_tz = pytz.timezone('Asia/Seoul')
            timestamp = datetime.now(seoul_tz)
        else:
            timestamp = capture_timestamp  # ìº¡ì²˜ ì‹œì ì˜ ì •í™•í•œ ì‹œê°„ ì‚¬ìš©
        
        upload_item = {
            'timestamp': timestamp,
            'frame_path': frame_path,
            'video_path': video_path,
            'result_data': result_data,
            'uploaded': False,
            'retry_count': 0
        }
        
        self.upload_queue.append(upload_item)
        self.logger.info(f"S3 í ì¶”ê°€ - ëŒ€ê¸°ì¤‘: {len(self.upload_queue)}ê°œ")
    
    def _generate_s3_paths(self, timestamp):
        """S3 ê²½ë¡œ ìƒì„± (ì¤‘ë³µ ì œê±°ëœ êµ¬ì¡°)"""
        # timestampê°€ ì´ë¯¸ ì„œìš¸ ì‹œê°„ëŒ€ë©´ ê·¸ëŒ€ë¡œ, ì•„ë‹ˆë©´ ë³€í™˜
        if timestamp.tzinfo is None or timestamp.tzinfo.utcoffset(timestamp) is None:
            # naive datetimeì´ë©´ ì„œìš¸ ì‹œê°„ëŒ€ë¡œ ê°€ì •
            seoul_tz = pytz.timezone('Asia/Seoul')
            dt = seoul_tz.localize(timestamp)
        else:
            # timezone-aware datetimeì´ë©´ ì„œìš¸ ì‹œê°„ëŒ€ë¡œ ë³€í™˜
            seoul_tz = pytz.timezone('Asia/Seoul')
            dt = timestamp.astimezone(seoul_tz)
        
        # S3 ì €ì¥ êµ¬ì¡° (ë²„í‚· ë‚´ë¶€): home-1/cam-1/2025/08/23/...
        folder_name = f"{dt.year:04d}{dt.month:02d}{dt.day:02d}_{dt.hour:02d}{dt.minute:02d}{dt.second:02d}_log"
        
        base_path = f"home-1/cam-1/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}/{folder_name}"
        file_prefix = f"{dt.year:04d}{dt.month:02d}{dt.day:02d}_{dt.hour:02d}{dt.minute:02d}{dt.second:02d}"
        
        # JSONì˜ image_keyëŠ” ì „ì²´ ê²½ë¡œ (doorbox-data í¬í•¨)
        image_key_full_path = f"doorbox-data/home-1/cam-1/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}/{folder_name}/{file_prefix}_frame.jpg"
        
        return {
            'base_path': base_path,
            'frame_key': f"{base_path}/{file_prefix}_frame.jpg",
            'video_key': f"{base_path}/{file_prefix}_clip.mp4",
            'result_key': f"{base_path}/{file_prefix}_result.json",
            'image_key_full_path': image_key_full_path  # JSONìš© ì „ì²´ ê²½ë¡œ
        }
    
    def _upload_file_to_s3(self, local_path, s3_key, content_type):
        """ë‹¨ì¼ íŒŒì¼ S3 ì—…ë¡œë“œ"""
        try:
            with open(local_path, 'rb') as f:
                self.s3_client.put_object(
                    Bucket=config.AWS_BUCKET_NAME,
                    Key=s3_key,
                    Body=f,
                    ContentType=content_type
                )
            return True
        except Exception as e:
            self.logger.error(f"S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {s3_key}, ì˜¤ë¥˜: {e}")
            return False
    
    def _upload_json_to_s3(self, data, s3_key):
        """JSON ë°ì´í„° S3 ì—…ë¡œë“œ"""
        try:
            self.s3_client.put_object(
                Bucket=config.AWS_BUCKET_NAME,
                Key=s3_key,
                Body=json.dumps(data, ensure_ascii=False, indent=2),
                ContentType='application/json'
            )
            return True
        except Exception as e:
            self.logger.error(f"JSON ì—…ë¡œë“œ ì‹¤íŒ¨: {s3_key}, ì˜¤ë¥˜: {e}")
            return False
    
    def _generate_unique_filename(self, base_timestamp_str):
        """ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê³ ìœ  íŒŒì¼ëª… ìƒì„±"""
        with self.filename_lock:
            if base_timestamp_str in self.filename_counter:
                self.filename_counter[base_timestamp_str] += 1
                counter = self.filename_counter[base_timestamp_str]
                return f"{base_timestamp_str}_{counter:02d}"
            else:
                self.filename_counter[base_timestamp_str] = 0
                return base_timestamp_str
    
    def _generate_s3_paths_with_custom_filename(self, timestamp, custom_filename):
        """ì»¤ìŠ¤í…€ íŒŒì¼ëª…ì„ ì‚¬ìš©í•œ S3 ê²½ë¡œ ìƒì„±"""
        # timestampê°€ ì´ë¯¸ ì„œìš¸ ì‹œê°„ëŒ€ë©´ ê·¸ëŒ€ë¡œ, ì•„ë‹ˆë©´ ë³€í™˜
        if timestamp.tzinfo is None or timestamp.tzinfo.utcoffset(timestamp) is None:
            seoul_tz = pytz.timezone('Asia/Seoul')
            dt = seoul_tz.localize(timestamp)
        else:
            seoul_tz = pytz.timezone('Asia/Seoul')
            dt = timestamp.astimezone(seoul_tz)
        
        # â˜… custom_filename ì‚¬ìš©
        folder_name = f"{custom_filename}_log"
        
        base_path = f"home-1/cam-1/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}/{folder_name}"
        
        # JSONì˜ image_keyëŠ” ì „ì²´ ê²½ë¡œ (doorbox-data í¬í•¨)
        image_key_full_path = f"doorbox-data/home-1/cam-1/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}/{folder_name}/{custom_filename}_frame.jpg"
        
        return {
            'base_path': base_path,
            'frame_key': f"{base_path}/{custom_filename}_frame.jpg",
            'video_key': f"{base_path}/{custom_filename}_clip.mp4",
            'result_key': f"{base_path}/{custom_filename}_result.json",
            'image_key_full_path': image_key_full_path
        }
    
    def _process_upload_batch(self):
        """ë°°ì¹˜ ì—…ë¡œë“œ ì²˜ë¦¬"""
        if not self.upload_queue:
            return
        
        items_to_process = [item for item in self.upload_queue[:config.UPLOAD_BATCH_SIZE] 
                           if not item['uploaded'] and item['retry_count'] < 3]
        
        for item in items_to_process:
            try:
                s3_paths = self._generate_s3_paths(item['timestamp'])
                
                # JSONì— ì´ë¯¸ image_keyê°€ ì„¤ì •ë˜ì–´ ìˆìŒ
                # ë³„ë„ë¡œ ì„¤ì •í•  í•„ìš” ì—†ìŒ
                
                # 1. JSON ì—…ë¡œë“œ
                if self._upload_json_to_s3(item['result_data'], s3_paths['result_key']):
                    self.logger.info(f"âœ… JSON: {s3_paths['result_key']}")
                else:
                    item['retry_count'] += 1
                    continue
                
                # 2. í”„ë ˆì„ ì—…ë¡œë“œ
                if os.path.exists(item['frame_path']):
                    if self._upload_file_to_s3(item['frame_path'], s3_paths['frame_key'], 'image/jpeg'):
                        self.logger.info(f"âœ… í”„ë ˆì„: {s3_paths['frame_key']}")
                        os.remove(item['frame_path'])
                    else:
                        item['retry_count'] += 1
                        continue
                
                # 3. ë¹„ë””ì˜¤ ì—…ë¡œë“œ
                if item['video_path'] and os.path.exists(item['video_path']):
                    if self._upload_file_to_s3(item['video_path'], s3_paths['video_key'], 'video/mp4'):
                        self.logger.info(f"âœ… ë¹„ë””ì˜¤: {s3_paths['video_key']}")
                        os.remove(item['video_path'])
                    else:
                        item['retry_count'] += 1
                        continue
                
                item['uploaded'] = True
                self.logger.info(f"ì—…ë¡œë“œ ì™„ë£Œ: {s3_paths['base_path']}")
                
            except Exception as e:
                self.logger.error(f"ì—…ë¡œë“œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                item['retry_count'] += 1
        
        # ì™„ë£Œ/ì‹¤íŒ¨ ì•„ì´í…œ ì œê±°
        self.upload_queue = [item for item in self.upload_queue 
                           if not item['uploaded'] and item['retry_count'] < 3]
        
        if items_to_process:
            self.logger.info(f"ë°°ì¹˜ ì™„ë£Œ - ë‚¨ì€ í: {len(self.upload_queue)}ê°œ")
    
    def _detect_green_boxes(self, frame):
        """ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ê²€ì¶œ"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        lower_green = np.array([40, 50, 50])
        upper_green = np.array([80, 255, 255])
        
        mask = cv2.inRange(hsv, lower_green, upper_green)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        boxes = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 250 * 250:
                x, y, w, h = cv2.boundingRect(contour)
                boxes.append((x, y, w, h))
        
        return boxes
    
    def _expand_bbox(self, bbox, frame_shape, scale=1.5):
        """ë°”ìš´ë”© ë°•ìŠ¤ 1.5ë°° í™•ì¥"""
        x, y, w, h = bbox
        frame_h, frame_w = frame_shape[:2]
        
        center_x = x + w // 2
        center_y = y + h // 2
        
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        new_x = max(0, center_x - new_w // 2)
        new_y = max(0, center_y - new_h // 2)
        
        new_x = min(new_x, frame_w - new_w)
        new_y = min(new_y, frame_h - new_h)
        new_w = min(new_w, frame_w - new_x)
        new_h = min(new_h, frame_h - new_y)
        
        return new_x, new_y, new_w, new_h
    
    def _save_detection_results(self, frame, classification_results, capture_timestamp, timestamp_str):
        """ê°ì§€ ê²°ê³¼ ì €ì¥ ë° S3 í ì¶”ê°€"""
        try:
            frame_filename = f"{timestamp_str}_frame.jpg"
            video_filename = f"{timestamp_str}_clip.mp4"
            result_filename = f"{timestamp_str}_result.json"
            
            frame_path = os.path.join(config.LOCAL_FRAMES_DIR, frame_filename)
            video_path = os.path.join(config.LOCAL_VIDEOS_DIR, video_filename)
            result_path = os.path.join(config.LOCAL_RESULTS_DIR, result_filename)
            
            # â˜… íŒŒì¼ ì¤‘ë³µ ì²´í¬ (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
            if os.path.exists(frame_path):
                self.logger.warning(f"íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•¨: {frame_filename} - ë®ì–´ì“°ê¸°")
            
            # 1. í”„ë ˆì„ ì €ì¥
            cv2.imwrite(frame_path, frame)
            self.logger.info(f"í”„ë ˆì„ ì €ì¥: {frame_filename}")
            
            # 2. 5ì´ˆ í´ë¦½ ì €ì¥
            detection_time = time.time()
            clip_saved = self._save_video_clip(detection_time, video_path)
            
            if clip_saved:
                self.logger.info(f"ë¹„ë””ì˜¤ ì €ì¥: {video_filename}")
            else:
                self.logger.warning("ë¹„ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨")
                video_path = None
            
            # 3. JSON ë°ì´í„° ìƒì„± - timestamp_strì— ë§ì¶° S3 ê²½ë¡œë„ ì¡°ì •
            s3_paths = self._generate_s3_paths_with_custom_filename(capture_timestamp, timestamp_str)
            result_data = {
                "day": capture_timestamp.strftime("%Y%m%d"),
                "time": capture_timestamp.strftime("%H:%M:%S"),
                "image_key": s3_paths['image_key_full_path'],
                "detection_results": {
                    "accessory": classification_results.get("accessory"),
                    "emotion": classification_results.get("emotion"),
                    "gender": classification_results.get("gender"),
                    "age_group": classification_results.get("age_group")
                }
            }
            
            # 4. ë¡œì»¬ì— JSON íŒŒì¼ ì €ì¥
            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            self.logger.info(f"ê²°ê³¼ JSON ì €ì¥: {result_filename}")
            
            # 5. S3 ì—…ë¡œë“œ íì— ì¶”ê°€ - capture_timestamp ì‚¬ìš©
            self._queue_upload_data(frame_path, video_path, result_data, capture_timestamp)
            
            # 6. â˜… ìƒì„¸ ë¡œê·¸ ì¶œë ¥ (ê³ ìœ  íŒŒì¼ëª… ë° ëŒ€ê¸° ìº¡ì²˜ ìˆ˜ í¬í•¨)
            emotion = classification_results.get("emotion", "unknown")
            emotion_conf = classification_results.get("emotion_confidence", 0.0)
            accessory = classification_results.get("accessory")
            gender = classification_results.get("gender", "unknown")
            gender_conf = classification_results.get("gender_confidence", 0.0)
            age_group = classification_results.get("age_group", "unknown")
            age_conf = classification_results.get("age_confidence", 0.0)
            
            # ì•…ì„¸ì„œë¦¬ ìƒíƒœ í…ìŠ¤íŠ¸ (confidence ì—†ìŒ)
            if accessory is True:
                accessory_text = "ë§ˆìŠ¤í¬ ì°©ìš©"
            elif accessory is False:
                accessory_text = "ë§ˆìŠ¤í¬ ì—†ìŒ"
            else:
                accessory_text = "ë§ˆìŠ¤í¬ ë¯¸íŒë³„"
            
            # â˜… ê°œì„ ëœ ë¡œê·¸ ì¶œë ¥ (íŒŒì¼ëª… ë° ëŒ€ê¸° ìƒíƒœ í¬í•¨)
            self.logger.info("=" * 50)
            self.logger.info(f"ğŸ–¼ï¸  í”„ë ˆì„ íŒŒì¼: {frame_filename}")
            self.logger.info(f"ğŸ•’ ìº¡ì²˜ ì‹œê°„: {capture_timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
            self.logger.info(f"ğŸ“Š ëŒ€ê¸° ì¤‘ì¸ ìº¡ì²˜: {self.pending_captures}ê°œ")
            self.logger.info("=== ë¶„ë¥˜ ê²°ê³¼ ìƒì„¸ ===")
            self.logger.info(f"   ê°ì •: {emotion} (ì‹ ë¢°ë„: {emotion_conf:.3f})")
            self.logger.info(f"   ì•…ì„¸ì„œë¦¬: {accessory_text}")
            self.logger.info(f"   ì„±ë³„: {gender} (ì‹ ë¢°ë„: {gender_conf:.3f})")
            self.logger.info(f"   ì—°ë ¹ëŒ€: {age_group} (ì‹ ë¢°ë„: {age_conf:.3f})")
            self.logger.info("=" * 50)
            
            return True
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def _rtsp_capture_worker(self):
        """RTSP ìº¡ì²˜ ìŠ¤ë ˆë“œ (ìµœì í™”)"""
        self.cap = cv2.VideoCapture(self.rtsp_url)
        
        if not self.cap.isOpened():
            self.logger.error("RTSP ì—°ê²° ì‹¤íŒ¨")
            return
        
        # RTSP ìŠ¤íŠ¸ë¦¼ ìµœì í™” ì„¤ì •
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ í¬ê¸° ìµœì†Œí™” (ì§€ì—° ì‹œê°„ ê°ì†Œ)
        self.cap.set(cv2.CAP_PROP_FPS, 30)        # FPS ì„¤ì •
        
        # ì´ˆê¸° ëª‡ í”„ë ˆì„ì€ ë²„ë¦¼ (ì—°ê²° ì•ˆì •í™”)
        for _ in range(5):
            self.cap.read()
        
        self.logger.info("RTSP ìŠ¤íŠ¸ë¦¼ ì‹œì‘ (ìµœì í™”ë¨)")
        
        frame_count = 0
        while self.running:
            ret, frame = self.cap.read()
            if ret:
                with self.frame_lock:
                    self.latest_frame = frame.copy()
                frame_count += 1
                
            else:
                self.logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                time.sleep(0.01)  # ì§§ì€ ëŒ€ê¸°
            
            # CPU ì‚¬ìš©ë¥  ìµœì í™”
            time.sleep(0.001)  # 1ms ëŒ€ê¸° (ê¸°ì¡´ 0.1ì´ˆì—ì„œ ë‹¨ì¶•)
        
        self.cap.release()
        self.logger.info("RTSP ìº¡ì²˜ ì¢…ë£Œ")
    
    def _serial_reader_worker(self):
        """ì‹œë¦¬ì–¼ í†µì‹  ìŠ¤ë ˆë“œ (ìµœì í™”)"""
        try:
            self.ser = serial.Serial(self.serial_port, self.serial_baudrate, timeout=0.1)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
            self.logger.info(f"ì‹œë¦¬ì–¼ ì—°ê²° ì„±ê³µ: {self.serial_port}")
        except Exception as e:
            self.logger.error(f"ì‹œë¦¬ì–¼ ì—°ê²° ì‹¤íŒ¨: {e}")
            return
        
        while self.running:
            try:
                if self.ser.in_waiting > 0:
                    line = self.ser.readline().decode('utf-8').strip()
                    if line:
                        # YOLO ê°ì§€ ê²°ê³¼ë§Œ ì²˜ë¦¬ (ë¡œê·¸ ì¶œë ¥ ì•ˆí•¨)
                        if "[print_yolo_result]" in line and "[AI coordinate]" in line:
                            self._process_yolo_detection(line)
                        # ë‹¤ë¥¸ ì‹œë¦¬ì–¼ ë©”ì‹œì§€ëŠ” ë¬´ì‹œ
                
                time.sleep(0.001)  # 1ms ëŒ€ê¸° (ê¸°ì¡´ 0.1ì´ˆì—ì„œ ë‹¨ì¶•)
                
            except Exception as e:
                self.logger.error(f"ì‹œë¦¬ì–¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                time.sleep(0.1)
        
        if self.ser:
            self.ser.close()
        self.logger.info("ì‹œë¦¬ì–¼ í†µì‹  ì¢…ë£Œ")
    
    def _process_yolo_detection(self, yolo_line):
        """YOLO ê°ì§€ ê²°ê³¼ ì²˜ë¦¬"""
        current_time = time.time()
        
        if not self.detection_active:
            # ìƒˆë¡œìš´ ê°ì§€ ì„¸ì…˜ ì‹œì‘
            self.detection_active = True
            self.first_detection_time = current_time
            self.detection_session_id = int(current_time)
            self.last_capture_time = None
            self.last_successful_capture_time = 0
            self.pending_captures = 0
            
            # â˜… ê¸°ì¡´ íƒ€ì´ë¨¸ê°€ ìˆìœ¼ë©´ ì·¨ì†Œ
            if self.capture_timer:
                self.capture_timer.cancel()
                self.capture_timer = None
            
            self.logger.info(f"ìƒˆë¡œìš´ ê°ì§€ ì„¸ì…˜ ì‹œì‘ (ID: {self.detection_session_id})")
            
            # ì²« ê°ì§€ í›„ ì¦‰ì‹œ ë˜ëŠ” ì§€ì—° í›„ ìº¡ì²˜ ì‹œì‘
            if config.DETECTION_DELAY > 0:
                self.capture_timer = threading.Timer(config.DETECTION_DELAY, self._start_periodic_capture)
                self.capture_timer.start()
                self.logger.info(f"{config.DETECTION_DELAY}ì´ˆ í›„ ìº¡ì²˜ ì‹œì‘ ì˜ˆì •")
            else:
                self._start_periodic_capture()
        
        # ê°ì§€ ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬
        if current_time - self.first_detection_time > config.DETECTION_TIMEOUT:
            self._end_detection_session()
    
    def _start_periodic_capture(self):
        """ì£¼ê¸°ì  ìº¡ì²˜ ì‹œì‘"""
        if not self.detection_active:
            return
        
        # â˜… ìºìŠ¤ì¼€ì´ë”© íƒ€ì´ë¨¸ ë°©ì§€
        if self.capture_timer:
            self.capture_timer.cancel()
            self.capture_timer = None
        
        self.logger.info("ìº¡ì²˜ ë° ë¶„ë¥˜ ì‹œì‘")
        
        # â˜… ìŠ¤ë ˆë“œì—ì„œ ìº¡ì²˜ ì‹¤í–‰ (ë©”ì¸ íƒ€ì´ë¨¸ ë¸”ë¡œí‚¹ ë°©ì§€)
        capture_thread = threading.Thread(target=self._execute_capture_safely, daemon=True)
        capture_thread.start()
        
        # ë‹¤ìŒ ìº¡ì²˜ ìŠ¤ì¼€ì¤„ë§
        if self.detection_active:
            self.capture_timer = threading.Timer(config.CAPTURE_INTERVAL, self._start_periodic_capture)
            self.capture_timer.start()
    
    def _execute_capture_safely(self):
        """ì•ˆì „í•œ ìº¡ì²˜ ì‹¤í–‰"""
        with self.capture_lock:
            if self.capture_in_progress:
                self.logger.debug("ì´ë¯¸ ìº¡ì²˜ê°€ ì§„í–‰ ì¤‘ - ê±´ë„ˆëœ€")
                return
            
            current_time = time.time()
            
            # â˜… ìµœì†Œ ê°„ê²© ì²´í¬ (ì¤‘ë³µ ìº¡ì²˜ ë°©ì§€)
            min_interval = getattr(config, 'MIN_CAPTURE_INTERVAL', 3.0)
            if current_time - self.last_successful_capture_time < min_interval:
                self.logger.debug(f"ìµœì†Œ ê°„ê²©({min_interval}ì´ˆ) ë¯¸ë‹¬ - ê±´ë„ˆëœ€")
                return
            
            self.capture_in_progress = True
            self.pending_captures += 1
        
        try:
            # ì‹¤ì œ ìº¡ì²˜ ë° ì²˜ë¦¬ ì‹¤í–‰
            success = self._capture_and_process()
            if success:
                self.last_successful_capture_time = time.time()
        except Exception as e:
            self.logger.error(f"ìº¡ì²˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            with self.capture_lock:
                self.capture_in_progress = False
                self.pending_captures = max(0, self.pending_captures - 1)
    
    def _capture_and_process(self):
        """ìº¡ì²˜ ë° ì²˜ë¦¬ ì‹¤í–‰"""
        current_time = time.time()
        
        # ê°ì§€ ì„¸ì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if not self.detection_active:
            return
        
        # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬
        if current_time - self.first_detection_time > config.DETECTION_TIMEOUT:
            self._end_detection_session()
            return
        
        # â˜… ìº¡ì²˜ ì‹œì ì˜ ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (ë¡œê·¸ì™€ íŒŒì¼ëª… ë™ê¸°í™”)
        seoul_tz = pytz.timezone('Asia/Seoul')
        capture_timestamp = datetime.now(seoul_tz)  # ìº¡ì²˜ ì‹œì ì˜ ì •í™•í•œ ì‹œê°„
        
        with self.frame_lock:
            if self.latest_frame is None:
                self.logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ì´ ì—†ìŒ")
                return
            current_frame = self.latest_frame.copy()
        
        # ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ê²€ì¶œ
        boxes = self._detect_green_boxes(current_frame)
        
        if not boxes:
            self.logger.info("ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ì—†ìŒ - ìº¡ì²˜ ê±´ë„ˆëœ€")
            return
        
        # ê°€ì¥ í° ë°•ìŠ¤ ì„ íƒ
        largest_box = max(boxes, key=lambda box: box[2] * box[3])
        
        # ë°•ìŠ¤ í™•ì¥
        expanded_box = self._expand_bbox(largest_box, current_frame.shape)
        x, y, w, h = expanded_box
        
        # ì–¼êµ´ ì˜ì—­ í¬ë¡­
        face_crop = current_frame[y:y+h, x:x+w]
        
        if face_crop.size == 0:
            self.logger.warning("í¬ë¡­ëœ ì–¼êµ´ ì˜ì—­ì´ ë¹„ì–´ìˆìŒ")
            return False
        
        # â˜… ê³ ìœ  íŒŒì¼ëª… ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        base_timestamp_str = capture_timestamp.strftime("%Y%m%d_%H%M%S")
        unique_timestamp_str = self._generate_unique_filename(base_timestamp_str)
        
        # ëª¨ë“  ëª¨ë¸ë¡œ ë¶„ë¥˜ ì‹¤í–‰
        classification_results = self._classify_all_models(face_crop)
        
        # â˜… ê²°ê³¼ ì €ì¥ (ê³ ìœ  íŒŒì¼ëª… ì‚¬ìš©)
        success = self._save_detection_results(
            current_frame, 
            classification_results, 
            capture_timestamp, 
            unique_timestamp_str
        )
        
        if success:
            self.last_capture_time = current_time
            return True
        
        return False
    
    def _end_detection_session(self):
        """ê°ì§€ ì„¸ì…˜ ì¢…ë£Œ"""
        if self.detection_active:
            self.logger.info(f"ê°ì§€ ì„¸ì…˜ ì¢…ë£Œ (ID: {self.detection_session_id})")
            
            # â˜… í™œì„± íƒ€ì´ë¨¸ ì·¨ì†Œ
            if self.capture_timer:
                self.capture_timer.cancel()
                self.capture_timer = None
            
            self.detection_active = False
            self.first_detection_time = None
            self.last_capture_time = None
            self.detection_session_id = None
            self.last_successful_capture_time = 0
            
            # â˜… íŒŒì¼ëª… ì¹´ìš´í„° ì •ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
            with self.filename_lock:
                # ì˜¤ë˜ëœ í•­ëª© ì •ë¦¬ (1ì‹œê°„ ì´ìƒ ëœ ê²ƒë“¤)
                current_time = time.time()
                keys_to_remove = []
                for filename in self.filename_counter.keys():
                    try:
                        # íŒŒì¼ëª…ì—ì„œ ì‹œê°„ ì¶”ì¶œ (YYYYMMDD_HHMMSS í˜•ì‹)
                        if '_' in filename:
                            parts = filename.split('_')
                            if len(parts) >= 2:
                                date_part = parts[0]  # YYYYMMDD
                                time_part = parts[1]  # HHMMSS
                                datetime_str = date_part + time_part
                                file_time = datetime.strptime(datetime_str, '%Y%m%d%H%M%S').timestamp()
                                if current_time - file_time > 3600:  # 1ì‹œê°„
                                    keys_to_remove.append(filename)
                    except:
                        # íŒŒì‹± ì‹¤íŒ¨í•œ ì˜¤ë˜ëœ í‚¤ë“¤ë„ ì œê±°
                        keys_to_remove.append(filename)
                
                for key in keys_to_remove:
                    del self.filename_counter[key]
                
                if keys_to_remove:
                    self.logger.debug(f"íŒŒì¼ëª… ì¹´ìš´í„° ì •ë¦¬: {len(keys_to_remove)}ê°œ ì œê±°")
    
    # â˜… ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    def search_logs_by_filename(self, filename_pattern):
        """íŒŒì¼ëª… íŒ¨í„´ìœ¼ë¡œ ë¡œê·¸ ê²€ìƒ‰ (ë””ë²„ê¹…ìš©)"""
        log_file = config.LOG_FILE
        results = []
        
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
            in_classification_block = False
            current_block = []
            
            for line in lines:
                if filename_pattern in line and "í”„ë ˆì„ íŒŒì¼:" in line:
                    in_classification_block = True
                    current_block = [line.strip()]
                elif in_classification_block:
                    current_block.append(line.strip())
                    if "=" * 50 in line:  # ë¸”ë¡ ì¢…ë£Œ
                        results.append('\n'.join(current_block))
                        in_classification_block = False
                        current_block = []
        
        except Exception as e:
            self.logger.error(f"ë¡œê·¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return results
    
    def debug_classification_by_file(self, frame_filename):
        """íŠ¹ì • í”„ë ˆì„ íŒŒì¼ì˜ ë¶„ë¥˜ ê²°ê³¼ ì¡°íšŒ"""
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
        base_name = frame_filename.replace('_frame.jpg', '').replace('.jpg', '')
        
        # ë¡œê·¸ì—ì„œ í•´ë‹¹ íŒŒì¼ì˜ ë¶„ë¥˜ ê²°ê³¼ ê²€ìƒ‰
        results = self.search_logs_by_filename(base_name)
        
        if results:
            print(f"\nğŸ” {frame_filename}ì˜ ë¶„ë¥˜ ê²°ê³¼:")
            for result in results:
                print(result)
        else:
            print(f"âŒ {frame_filename}ì— ëŒ€í•œ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return results
    
    def start(self):
        """ì‹œìŠ¤í…œ ì‹œì‘"""
        self.running = True
        
        # ë¹„ë””ì˜¤ ë²„í¼ë§ ì‹œì‘
        self._start_video_buffering()
        
        # S3 ì—…ë¡œë” ì‹œì‘
        self._start_s3_uploader()
        
        # RTSP ìº¡ì²˜ ìŠ¤ë ˆë“œ ì‹œì‘
        self.rtsp_thread = threading.Thread(target=self._rtsp_capture_worker, daemon=True)
        self.rtsp_thread.start()
        
        # ì‹œë¦¬ì–¼ ë¦¬ë” ìŠ¤ë ˆë“œ ì‹œì‘
        self.serial_thread = threading.Thread(target=self._serial_reader_worker, daemon=True)
        self.serial_thread.start()
        
        self.logger.info("DoorBox ì‹œìŠ¤í…œ ì‹œì‘ë¨")
        
        # ë©”ì¸ ë£¨í”„
        try:
            while self.running:
                time.sleep(1)
        except KeyboardInterrupt:
            self.logger.info("í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ ê°ì§€")
            self.stop()
    
    def stop(self):
        """ì‹œìŠ¤í…œ ì¢…ë£Œ"""
        self.logger.info("ğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
        
        self.running = False
        
        # ë¹„ë””ì˜¤ ë ˆì½”ë” ì¢…ë£Œ
        self.recording = False
        if self.buffer_thread:
            self.buffer_thread.join(timeout=2)
        
        # S3 ì—…ë¡œë” ì¢…ë£Œ (ë‚¨ì€ í ì²˜ë¦¬)
        if self.upload_queue:
            self.logger.info("ë‚¨ì€ ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘...")
            self._process_upload_batch()
        
        self.upload_running = False
        if self.upload_thread:
            self.upload_thread.join(timeout=5)
        
        # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if self.rtsp_thread:
            self.rtsp_thread.join(timeout=3)
        if self.serial_thread:
            self.serial_thread.join(timeout=3)
        
        self.logger.info("âœ… DoorBox ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    doorbox = DoorBoxInferenceSystem()
    
    try:
        doorbox.start()
    except Exception as e:
        logging.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    finally:
        doorbox.stop()

if __name__ == "__main__":
    main()
